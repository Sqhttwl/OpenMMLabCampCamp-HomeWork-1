2023-02-09 20:30:46,204 - mmdet - INFO - Environment info:
------------------------------------------------------------
sys.platform: linux
Python: 3.8.16 (default, Jan 17 2023, 23:13:24) [GCC 11.2.0]
CUDA available: True
GPU 0: NVIDIA GeForce RTX 3090
CUDA_HOME: /data/apps/cuda/11.1
NVCC: Cuda compilation tools, release 11.1, V11.1.74
GCC: gcc (GCC) 7.3.0
PyTorch: 1.10.0+cu111
PyTorch compiling details: PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.0 Product Build 20191122 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v2.2.3 (Git Hash 7336ca9f055cf1bfa13efb658fe15dc9b41f0740)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86
  - CuDNN 8.0.5
  - Magma 2.5.2
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.1, CUDNN_VERSION=8.0.5, CXX_COMPILER=/opt/rh/devtoolset-7/root/usr/bin/c++, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -fopenmp -DNDEBUG -DUSE_KINETO -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -DEDGE_PROFILER_USE_KINETO -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-unused-local-typedefs -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=1.10.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, 

TorchVision: 0.11.0+cu111
OpenCV: 4.7.0
MMCV: 1.7.0
MMCV Compiler: GCC 7.3
MMCV CUDA Compiler: 11.1
MMDetection: 2.28.1+c14dd6c
------------------------------------------------------------

2023-02-09 20:30:46,455 - mmdet - INFO - Distributed training: False
2023-02-09 20:30:46,702 - mmdet - INFO - Config:
model = dict(
    type='MaskRCNN',
    backbone=dict(
        type='ResNet',
        depth=50,
        num_stages=4,
        out_indices=(0, 1, 2, 3),
        frozen_stages=1,
        norm_cfg=dict(type='BN', requires_grad=True),
        norm_eval=True,
        style='pytorch'),
    neck=dict(
        type='FPN',
        in_channels=[256, 512, 1024, 2048],
        out_channels=256,
        num_outs=5),
    rpn_head=dict(
        type='RPNHead',
        in_channels=256,
        feat_channels=256,
        anchor_generator=dict(
            type='AnchorGenerator',
            scales=[8],
            ratios=[0.5, 1.0, 2.0],
            strides=[4, 8, 16, 32, 64]),
        bbox_coder=dict(
            type='DeltaXYWHBBoxCoder',
            target_means=[0.0, 0.0, 0.0, 0.0],
            target_stds=[1.0, 1.0, 1.0, 1.0]),
        loss_cls=dict(
            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),
        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),
    roi_head=dict(
        type='StandardRoIHead',
        bbox_roi_extractor=dict(
            type='SingleRoIExtractor',
            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),
            out_channels=256,
            featmap_strides=[4, 8, 16, 32]),
        bbox_head=dict(
            type='Shared2FCBBoxHead',
            in_channels=256,
            fc_out_channels=1024,
            roi_feat_size=7,
            num_classes=20,
            bbox_coder=dict(
                type='DeltaXYWHBBoxCoder',
                target_means=[0.0, 0.0, 0.0, 0.0],
                target_stds=[0.1, 0.1, 0.2, 0.2]),
            reg_class_agnostic=False,
            loss_cls=dict(
                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),
            loss_bbox=dict(type='L1Loss', loss_weight=1.0))),
    train_cfg=dict(
        rpn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.7,
                neg_iou_thr=0.3,
                min_pos_iou=0.3,
                match_low_quality=True,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=256,
                pos_fraction=0.5,
                neg_pos_ub=-1,
                add_gt_as_proposals=False),
            allowed_border=-1,
            pos_weight=-1,
            debug=False),
        rpn_proposal=dict(
            nms_pre=2000,
            max_per_img=1000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=dict(
            assigner=dict(
                type='MaxIoUAssigner',
                pos_iou_thr=0.5,
                neg_iou_thr=0.5,
                min_pos_iou=0.5,
                match_low_quality=True,
                ignore_iof_thr=-1),
            sampler=dict(
                type='RandomSampler',
                num=512,
                pos_fraction=0.25,
                neg_pos_ub=-1,
                add_gt_as_proposals=True),
            mask_size=28,
            pos_weight=-1,
            debug=False)),
    test_cfg=dict(
        rpn=dict(
            nms_pre=1000,
            max_per_img=1000,
            nms=dict(type='nms', iou_threshold=0.7),
            min_bbox_size=0),
        rcnn=dict(
            score_thr=0.05,
            nms=dict(type='nms', iou_threshold=0.5),
            max_per_img=100,
            mask_thr_binary=0.5)))
dataset_type = 'VOCDataset'
data_root = '/data/public/PascalVOC/2007/'
img_norm_cfg = dict(
    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(type='LoadAnnotations', with_bbox=True),
    dict(type='Resize', img_scale=(1000, 600), keep_ratio=True),
    dict(type='RandomFlip', flip_ratio=0.5),
    dict(
        type='Normalize',
        mean=[123.675, 116.28, 103.53],
        std=[58.395, 57.12, 57.375],
        to_rgb=True),
    dict(type='Pad', size_divisor=32),
    dict(type='DefaultFormatBundle'),
    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
]
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(
        type='MultiScaleFlipAug',
        img_scale=(1000, 600),
        flip=False,
        transforms=[
            dict(type='Resize', keep_ratio=True),
            dict(type='RandomFlip'),
            dict(
                type='Normalize',
                mean=[123.675, 116.28, 103.53],
                std=[58.395, 57.12, 57.375],
                to_rgb=True),
            dict(type='Pad', size_divisor=32),
            dict(type='ImageToTensor', keys=['img']),
            dict(type='Collect', keys=['img'])
        ])
]
data = dict(
    samples_per_gpu=16,
    workers_per_gpu=8,
    train=dict(
        type='RepeatDataset',
        times=3,
        dataset=dict(
            type='VOCDataset',
            ann_file=
            '/data/public/PascalVOC/2007/VOC2007/ImageSets/Main/trainval.txt',
            img_prefix='/data/public/PascalVOC/2007/VOC2007/',
            pipeline=[
                dict(type='LoadImageFromFile'),
                dict(type='LoadAnnotations', with_bbox=True),
                dict(type='Resize', img_scale=(1000, 600), keep_ratio=True),
                dict(type='RandomFlip', flip_ratio=0.5),
                dict(
                    type='Normalize',
                    mean=[123.675, 116.28, 103.53],
                    std=[58.395, 57.12, 57.375],
                    to_rgb=True),
                dict(type='Pad', size_divisor=32),
                dict(type='DefaultFormatBundle'),
                dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels'])
            ])),
    val=dict(
        type='VOCDataset',
        ann_file='/data/public/PascalVOC/2007/VOC2007/ImageSets/Main/test.txt',
        img_prefix='/data/public/PascalVOC/2007/VOC2007/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1000, 600),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]),
    test=dict(
        type='VOCDataset',
        ann_file='/data/public/PascalVOC/2007/VOC2007/ImageSets/Main/test.txt',
        img_prefix='/data/public/PascalVOC/2007/VOC2007/',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(
                type='MultiScaleFlipAug',
                img_scale=(1000, 600),
                flip=False,
                transforms=[
                    dict(type='Resize', keep_ratio=True),
                    dict(type='RandomFlip'),
                    dict(
                        type='Normalize',
                        mean=[123.675, 116.28, 103.53],
                        std=[58.395, 57.12, 57.375],
                        to_rgb=True),
                    dict(type='Pad', size_divisor=32),
                    dict(type='ImageToTensor', keys=['img']),
                    dict(type='Collect', keys=['img'])
                ])
        ]))
evaluation = dict(interval=1, metric='mAP')
optimizer = dict(type='SGD', lr=0.02, momentum=0.9, weight_decay=0.0001)
optimizer_config = dict(grad_clip=None)
lr_config = dict(
    policy='step',
    warmup='linear',
    warmup_iters=500,
    warmup_ratio=0.001,
    step=[8, 11])
runner = dict(type='EpochBasedRunner', max_epochs=12)
checkpoint_config = dict(interval=1)
log_config = dict(interval=50, hooks=[dict(type='TextLoggerHook')])
custom_hooks = [dict(type='NumClassCheckHook')]
dist_params = dict(backend='nccl')
log_level = 'INFO'
load_from = '/HOME/scz0apy/run/mmdetection/checkpoint/mask_rcnn_r50_fpn_1x_coco_20200205-d4b0c5d6.pth'
resume_from = None
workflow = [('train', 1)]
opencv_num_threads = 0
mp_start_method = 'fork'
auto_scale_lr = dict(enable=False, base_batch_size=16)
work_dir = 'work/mask_rcnn_r50_fpn_1x_voc07'
auto_resume = False
gpu_ids = [0]

2023-02-09 20:30:46,704 - mmdet - INFO - Set random seed to 855626312, deterministic: False
2023-02-09 20:30:46,978 - mmdet - INFO - initialize ResNet with init_cfg [{'type': 'Kaiming', 'layer': 'Conv2d'}, {'type': 'Constant', 'val': 1, 'layer': ['_BatchNorm', 'GroupNorm']}]
2023-02-09 20:30:47,112 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-09 20:30:47,113 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-09 20:30:47,113 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-09 20:30:47,114 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-09 20:30:47,115 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-09 20:30:47,115 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-09 20:30:47,116 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-09 20:30:47,117 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-09 20:30:47,118 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-09 20:30:47,119 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-09 20:30:47,119 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-09 20:30:47,120 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-09 20:30:47,121 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-09 20:30:47,123 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-09 20:30:47,125 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-09 20:30:47,126 - mmdet - INFO - initialize Bottleneck with init_cfg {'type': 'Constant', 'val': 0, 'override': {'name': 'norm3'}}
2023-02-09 20:30:47,135 - mmdet - INFO - initialize FPN with init_cfg {'type': 'Xavier', 'layer': 'Conv2d', 'distribution': 'uniform'}
2023-02-09 20:30:47,152 - mmdet - INFO - initialize RPNHead with init_cfg {'type': 'Normal', 'layer': 'Conv2d', 'std': 0.01}
2023-02-09 20:30:47,155 - mmdet - INFO - initialize Shared2FCBBoxHead with init_cfg [{'type': 'Normal', 'std': 0.01, 'override': {'name': 'fc_cls'}}, {'type': 'Normal', 'std': 0.001, 'override': {'name': 'fc_reg'}}, {'type': 'Xavier', 'distribution': 'uniform', 'override': [{'name': 'shared_fcs'}, {'name': 'cls_fcs'}, {'name': 'reg_fcs'}]}]
Name of parameter - Initialization information

backbone.conv1.weight - torch.Size([64, 3, 7, 7]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer1.0.conv1.weight - torch.Size([64, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.0.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer1.0.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer1.0.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.0.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer1.0.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer1.0.conv3.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.0.bn3.weight - torch.Size([256]): 
ConstantInit: val=0, bias=0 

backbone.layer1.0.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer1.0.downsample.0.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.0.downsample.1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer1.0.downsample.1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer1.1.conv1.weight - torch.Size([64, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.1.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer1.1.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer1.1.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.1.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer1.1.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer1.1.conv3.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.1.bn3.weight - torch.Size([256]): 
ConstantInit: val=0, bias=0 

backbone.layer1.1.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer1.2.conv1.weight - torch.Size([64, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.2.bn1.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer1.2.bn1.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer1.2.conv2.weight - torch.Size([64, 64, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.2.bn2.weight - torch.Size([64]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer1.2.bn2.bias - torch.Size([64]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer1.2.conv3.weight - torch.Size([256, 64, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer1.2.bn3.weight - torch.Size([256]): 
ConstantInit: val=0, bias=0 

backbone.layer1.2.bn3.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer2.0.conv1.weight - torch.Size([128, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.0.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer2.0.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer2.0.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.0.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer2.0.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer2.0.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.0.bn3.weight - torch.Size([512]): 
ConstantInit: val=0, bias=0 

backbone.layer2.0.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer2.0.downsample.0.weight - torch.Size([512, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.0.downsample.1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer2.0.downsample.1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer2.1.conv1.weight - torch.Size([128, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.1.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer2.1.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer2.1.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.1.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer2.1.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer2.1.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.1.bn3.weight - torch.Size([512]): 
ConstantInit: val=0, bias=0 

backbone.layer2.1.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer2.2.conv1.weight - torch.Size([128, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.2.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer2.2.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer2.2.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.2.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer2.2.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer2.2.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.2.bn3.weight - torch.Size([512]): 
ConstantInit: val=0, bias=0 

backbone.layer2.2.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer2.3.conv1.weight - torch.Size([128, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.3.bn1.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer2.3.bn1.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer2.3.conv2.weight - torch.Size([128, 128, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.3.bn2.weight - torch.Size([128]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer2.3.bn2.bias - torch.Size([128]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer2.3.conv3.weight - torch.Size([512, 128, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer2.3.bn3.weight - torch.Size([512]): 
ConstantInit: val=0, bias=0 

backbone.layer2.3.bn3.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.0.conv1.weight - torch.Size([256, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.0.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.0.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.0.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.0.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.0.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.0.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.0.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

backbone.layer3.0.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.0.downsample.0.weight - torch.Size([1024, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.0.downsample.1.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.0.downsample.1.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.1.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.1.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.1.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.1.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.1.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.1.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.1.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.1.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

backbone.layer3.1.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.2.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.2.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.2.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.2.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.2.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.2.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.2.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.2.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

backbone.layer3.2.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.3.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.3.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.3.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.3.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.3.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.3.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.3.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.3.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

backbone.layer3.3.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.4.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.4.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.4.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.4.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.4.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.4.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.4.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.4.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

backbone.layer3.4.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.5.conv1.weight - torch.Size([256, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.5.bn1.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.5.bn1.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.5.conv2.weight - torch.Size([256, 256, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.5.bn2.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.5.bn2.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer3.5.conv3.weight - torch.Size([1024, 256, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer3.5.bn3.weight - torch.Size([1024]): 
ConstantInit: val=0, bias=0 

backbone.layer3.5.bn3.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer4.0.conv1.weight - torch.Size([512, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.0.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer4.0.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer4.0.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.0.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer4.0.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer4.0.conv3.weight - torch.Size([2048, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.0.bn3.weight - torch.Size([2048]): 
ConstantInit: val=0, bias=0 

backbone.layer4.0.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer4.0.downsample.0.weight - torch.Size([2048, 1024, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.0.downsample.1.weight - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer4.0.downsample.1.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer4.1.conv1.weight - torch.Size([512, 2048, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.1.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer4.1.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer4.1.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.1.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer4.1.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer4.1.conv3.weight - torch.Size([2048, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.1.bn3.weight - torch.Size([2048]): 
ConstantInit: val=0, bias=0 

backbone.layer4.1.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer4.2.conv1.weight - torch.Size([512, 2048, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.2.bn1.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer4.2.bn1.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer4.2.conv2.weight - torch.Size([512, 512, 3, 3]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.2.bn2.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer4.2.bn2.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

backbone.layer4.2.conv3.weight - torch.Size([2048, 512, 1, 1]): 
KaimingInit: a=0, mode=fan_out, nonlinearity=relu, distribution =normal, bias=0 

backbone.layer4.2.bn3.weight - torch.Size([2048]): 
ConstantInit: val=0, bias=0 

backbone.layer4.2.bn3.bias - torch.Size([2048]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.lateral_convs.0.conv.weight - torch.Size([256, 256, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.lateral_convs.1.conv.weight - torch.Size([256, 512, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.lateral_convs.2.conv.weight - torch.Size([256, 1024, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.lateral_convs.3.conv.weight - torch.Size([256, 2048, 1, 1]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.lateral_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.fpn_convs.0.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.0.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.fpn_convs.1.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.1.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.fpn_convs.2.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.2.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

neck.fpn_convs.3.conv.weight - torch.Size([256, 256, 3, 3]): 
XavierInit: gain=1, distribution=uniform, bias=0 

neck.fpn_convs.3.conv.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of MaskRCNN  

rpn_head.rpn_conv.weight - torch.Size([256, 256, 3, 3]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_conv.bias - torch.Size([256]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.weight - torch.Size([3, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_cls.bias - torch.Size([3]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.weight - torch.Size([12, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

rpn_head.rpn_reg.bias - torch.Size([12]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.fc_cls.weight - torch.Size([21, 1024]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.fc_cls.bias - torch.Size([21]): 
NormalInit: mean=0, std=0.01, bias=0 

roi_head.bbox_head.fc_reg.weight - torch.Size([80, 1024]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.fc_reg.bias - torch.Size([80]): 
NormalInit: mean=0, std=0.001, bias=0 

roi_head.bbox_head.shared_fcs.0.weight - torch.Size([1024, 12544]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.shared_fcs.0.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.shared_fcs.1.weight - torch.Size([1024, 1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 

roi_head.bbox_head.shared_fcs.1.bias - torch.Size([1024]): 
XavierInit: gain=1, distribution=uniform, bias=0 
2023-02-09 20:30:57,792 - mmdet - INFO - Automatic scaling of learning rate (LR) has been disabled.
2023-02-09 20:31:01,246 - mmdet - INFO - load checkpoint from local path: /HOME/scz0apy/run/mmdetection/checkpoint/mask_rcnn_r50_fpn_1x_coco_20200205-d4b0c5d6.pth
2023-02-09 20:31:01,535 - mmdet - WARNING - The model and loaded state dict do not match exactly

size mismatch for roi_head.bbox_head.fc_cls.weight: copying a param with shape torch.Size([81, 1024]) from checkpoint, the shape in current model is torch.Size([21, 1024]).
size mismatch for roi_head.bbox_head.fc_cls.bias: copying a param with shape torch.Size([81]) from checkpoint, the shape in current model is torch.Size([21]).
size mismatch for roi_head.bbox_head.fc_reg.weight: copying a param with shape torch.Size([320, 1024]) from checkpoint, the shape in current model is torch.Size([80, 1024]).
size mismatch for roi_head.bbox_head.fc_reg.bias: copying a param with shape torch.Size([320]) from checkpoint, the shape in current model is torch.Size([80]).
unexpected key in source state_dict: roi_head.mask_head.convs.0.conv.weight, roi_head.mask_head.convs.0.conv.bias, roi_head.mask_head.convs.1.conv.weight, roi_head.mask_head.convs.1.conv.bias, roi_head.mask_head.convs.2.conv.weight, roi_head.mask_head.convs.2.conv.bias, roi_head.mask_head.convs.3.conv.weight, roi_head.mask_head.convs.3.conv.bias, roi_head.mask_head.upsample.weight, roi_head.mask_head.upsample.bias, roi_head.mask_head.conv_logits.weight, roi_head.mask_head.conv_logits.bias

2023-02-09 20:31:01,537 - mmdet - INFO - Start running, host: scz0apy@g0009, work_dir: /data/run01/scz0apy/mmdetection/work/mask_rcnn_r50_fpn_1x_voc07
2023-02-09 20:31:01,537 - mmdet - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) StepLrUpdaterHook                  
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_train_iter:
(VERY_HIGH   ) StepLrUpdaterHook                  
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
 -------------------- 
after_train_iter:
(ABOVE_NORMAL) OptimizerHook                      
(NORMAL      ) CheckpointHook                     
(LOW         ) IterTimerHook                      
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) CheckpointHook                     
(LOW         ) EvalHook                           
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_epoch:
(NORMAL      ) NumClassCheckHook                  
(LOW         ) IterTimerHook                      
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
before_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_iter:
(LOW         ) IterTimerHook                      
 -------------------- 
after_val_epoch:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
after_run:
(VERY_LOW    ) TextLoggerHook                     
 -------------------- 
2023-02-09 20:31:01,538 - mmdet - INFO - workflow: [('train', 1)], max: 12 epochs
2023-02-09 20:31:01,538 - mmdet - INFO - Checkpoints will be saved to /data/run01/scz0apy/mmdetection/work/mask_rcnn_r50_fpn_1x_voc07 by HardDiskBackend.
2023-02-09 20:31:50,573 - mmdet - INFO - Epoch [1][50/940]	lr: 1.978e-03, eta: 3:03:03, time: 0.978, data_time: 0.101, memory: 14584, loss_rpn_cls: 0.0160, loss_rpn_bbox: 0.0122, loss_cls: 1.0418, acc: 79.6079, loss_bbox: 0.3109, loss: 1.3809
2023-02-09 20:32:31,480 - mmdet - INFO - Epoch [1][100/940]	lr: 3.976e-03, eta: 2:47:20, time: 0.818, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0099, loss_rpn_bbox: 0.0107, loss_cls: 0.2914, acc: 92.8372, loss_bbox: 0.2866, loss: 0.5985
2023-02-09 20:33:12,572 - mmdet - INFO - Epoch [1][150/940]	lr: 5.974e-03, eta: 2:41:49, time: 0.821, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0087, loss_rpn_bbox: 0.0115, loss_cls: 0.2180, acc: 94.1763, loss_bbox: 0.2430, loss: 0.4812
2023-02-09 20:33:54,140 - mmdet - INFO - Epoch [1][200/940]	lr: 7.972e-03, eta: 2:39:14, time: 0.832, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0088, loss_rpn_bbox: 0.0126, loss_cls: 0.1454, acc: 95.5298, loss_bbox: 0.2022, loss: 0.3690
2023-02-09 20:34:35,204 - mmdet - INFO - Epoch [1][250/940]	lr: 9.970e-03, eta: 2:37:00, time: 0.821, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0096, loss_rpn_bbox: 0.0124, loss_cls: 0.1205, acc: 95.9045, loss_bbox: 0.1700, loss: 0.3124
2023-02-09 20:35:16,604 - mmdet - INFO - Epoch [1][300/940]	lr: 1.197e-02, eta: 2:35:30, time: 0.828, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0080, loss_rpn_bbox: 0.0122, loss_cls: 0.1119, acc: 96.0935, loss_bbox: 0.1647, loss: 0.2967
2023-02-09 20:35:57,549 - mmdet - INFO - Epoch [1][350/940]	lr: 1.397e-02, eta: 2:33:59, time: 0.819, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0074, loss_rpn_bbox: 0.0119, loss_cls: 0.1097, acc: 96.0830, loss_bbox: 0.1584, loss: 0.2874
2023-02-09 20:36:38,860 - mmdet - INFO - Epoch [1][400/940]	lr: 1.596e-02, eta: 2:32:50, time: 0.825, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0087, loss_rpn_bbox: 0.0121, loss_cls: 0.1169, acc: 95.9968, loss_bbox: 0.1574, loss: 0.2950
2023-02-09 20:37:19,900 - mmdet - INFO - Epoch [1][450/940]	lr: 1.796e-02, eta: 2:31:41, time: 0.821, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0073, loss_rpn_bbox: 0.0117, loss_cls: 0.1118, acc: 95.9971, loss_bbox: 0.1531, loss: 0.2839
2023-02-09 20:38:00,975 - mmdet - INFO - Epoch [1][500/940]	lr: 1.996e-02, eta: 2:30:40, time: 0.822, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0076, loss_rpn_bbox: 0.0132, loss_cls: 0.1234, acc: 95.6624, loss_bbox: 0.1603, loss: 0.3046
2023-02-09 20:38:41,786 - mmdet - INFO - Epoch [1][550/940]	lr: 2.000e-02, eta: 2:29:35, time: 0.816, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0079, loss_rpn_bbox: 0.0121, loss_cls: 0.1088, acc: 96.0996, loss_bbox: 0.1460, loss: 0.2749
2023-02-09 20:39:22,544 - mmdet - INFO - Epoch [1][600/940]	lr: 2.000e-02, eta: 2:28:35, time: 0.816, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0064, loss_rpn_bbox: 0.0116, loss_cls: 0.1082, acc: 96.1448, loss_bbox: 0.1428, loss: 0.2689
2023-02-09 20:40:03,670 - mmdet - INFO - Epoch [1][650/940]	lr: 2.000e-02, eta: 2:27:43, time: 0.823, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0070, loss_rpn_bbox: 0.0117, loss_cls: 0.1105, acc: 96.0078, loss_bbox: 0.1469, loss: 0.2761
2023-02-09 20:40:44,106 - mmdet - INFO - Epoch [1][700/940]	lr: 2.000e-02, eta: 2:26:43, time: 0.809, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0069, loss_rpn_bbox: 0.0120, loss_cls: 0.1076, acc: 96.1985, loss_bbox: 0.1433, loss: 0.2698
2023-02-09 20:41:24,908 - mmdet - INFO - Epoch [1][750/940]	lr: 2.000e-02, eta: 2:25:50, time: 0.816, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0066, loss_rpn_bbox: 0.0120, loss_cls: 0.1038, acc: 96.1787, loss_bbox: 0.1493, loss: 0.2716
2023-02-09 20:42:05,513 - mmdet - INFO - Epoch [1][800/940]	lr: 2.000e-02, eta: 2:24:55, time: 0.811, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0067, loss_rpn_bbox: 0.0114, loss_cls: 0.0998, acc: 96.4324, loss_bbox: 0.1359, loss: 0.2538
2023-02-09 20:42:46,189 - mmdet - INFO - Epoch [1][850/940]	lr: 2.000e-02, eta: 2:24:04, time: 0.814, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0067, loss_rpn_bbox: 0.0109, loss_cls: 0.0952, acc: 96.6265, loss_bbox: 0.1286, loss: 0.2415
2023-02-09 20:43:26,944 - mmdet - INFO - Epoch [1][900/940]	lr: 2.000e-02, eta: 2:23:15, time: 0.815, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0061, loss_rpn_bbox: 0.0111, loss_cls: 0.0972, acc: 96.4243, loss_bbox: 0.1339, loss: 0.2482
2023-02-09 20:43:59,353 - mmdet - INFO - Saving checkpoint at 1 epochs
2023-02-09 20:46:15,184 - mmdet - INFO - 
+-------------+------+-------+--------+-------+
| class       | gts  | dets  | recall | ap    |
+-------------+------+-------+--------+-------+
| aeroplane   | 285  | 756   | 0.933  | 0.851 |
| bicycle     | 337  | 1979  | 0.967  | 0.861 |
| bird        | 459  | 1558  | 0.946  | 0.819 |
| boat        | 263  | 1953  | 0.928  | 0.748 |
| bottle      | 469  | 2398  | 0.913  | 0.780 |
| bus         | 213  | 794   | 0.967  | 0.872 |
| car         | 1201 | 2476  | 0.968  | 0.892 |
| cat         | 358  | 1381  | 0.966  | 0.838 |
| chair       | 756  | 9757  | 0.943  | 0.702 |
| cow         | 244  | 884   | 0.951  | 0.853 |
| diningtable | 206  | 2094  | 0.971  | 0.761 |
| dog         | 489  | 1908  | 0.982  | 0.826 |
| horse       | 348  | 1331  | 0.963  | 0.885 |
| motorbike   | 325  | 1120  | 0.957  | 0.828 |
| person      | 4528 | 14074 | 0.969  | 0.880 |
| pottedplant | 480  | 1522  | 0.765  | 0.555 |
| sheep       | 242  | 691   | 0.946  | 0.836 |
| sofa        | 239  | 1549  | 0.967  | 0.809 |
| train       | 282  | 1411  | 0.968  | 0.859 |
| tvmonitor   | 308  | 815   | 0.896  | 0.777 |
+-------------+------+-------+--------+-------+
| mAP         |      |       |        | 0.812 |
+-------------+------+-------+--------+-------+
2023-02-09 20:46:15,224 - mmdet - INFO - Exp name: mask_rcnn_r50_fpn_1x_voc07.py
2023-02-09 20:46:15,224 - mmdet - INFO - Epoch(val) [1][4952]	mAP: 0.8116, AP50: 0.8120
2023-02-09 20:46:59,531 - mmdet - INFO - Epoch [2][50/940]	lr: 2.000e-02, eta: 2:16:45, time: 0.883, data_time: 0.081, memory: 14584, loss_rpn_cls: 0.0042, loss_rpn_bbox: 0.0099, loss_cls: 0.0855, acc: 96.8611, loss_bbox: 0.1242, loss: 0.2237
2023-02-09 20:47:40,443 - mmdet - INFO - Epoch [2][100/940]	lr: 2.000e-02, eta: 2:16:15, time: 0.818, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0051, loss_rpn_bbox: 0.0111, loss_cls: 0.0931, acc: 96.5398, loss_bbox: 0.1339, loss: 0.2433
2023-02-09 20:48:21,371 - mmdet - INFO - Epoch [2][150/940]	lr: 2.000e-02, eta: 2:15:45, time: 0.819, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0111, loss_cls: 0.0895, acc: 96.5754, loss_bbox: 0.1354, loss: 0.2407
2023-02-09 20:49:02,082 - mmdet - INFO - Epoch [2][200/940]	lr: 2.000e-02, eta: 2:15:11, time: 0.814, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0102, loss_cls: 0.0820, acc: 96.9133, loss_bbox: 0.1225, loss: 0.2187
2023-02-09 20:49:42,820 - mmdet - INFO - Epoch [2][250/940]	lr: 2.000e-02, eta: 2:14:38, time: 0.815, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0047, loss_rpn_bbox: 0.0108, loss_cls: 0.0878, acc: 96.7480, loss_bbox: 0.1295, loss: 0.2327
2023-02-09 20:50:23,847 - mmdet - INFO - Epoch [2][300/940]	lr: 2.000e-02, eta: 2:14:06, time: 0.820, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0114, loss_cls: 0.0851, acc: 96.7766, loss_bbox: 0.1243, loss: 0.2252
2023-02-09 20:51:04,877 - mmdet - INFO - Epoch [2][350/940]	lr: 2.000e-02, eta: 2:13:33, time: 0.821, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0110, loss_cls: 0.0871, acc: 96.6721, loss_bbox: 0.1297, loss: 0.2323
2023-02-09 20:51:46,318 - mmdet - INFO - Epoch [2][400/940]	lr: 2.000e-02, eta: 2:13:03, time: 0.829, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0046, loss_rpn_bbox: 0.0108, loss_cls: 0.0822, acc: 96.9070, loss_bbox: 0.1276, loss: 0.2251
2023-02-09 20:52:27,294 - mmdet - INFO - Epoch [2][450/940]	lr: 2.000e-02, eta: 2:12:28, time: 0.819, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0049, loss_rpn_bbox: 0.0104, loss_cls: 0.0884, acc: 96.7593, loss_bbox: 0.1210, loss: 0.2246
2023-02-09 20:53:08,175 - mmdet - INFO - Epoch [2][500/940]	lr: 2.000e-02, eta: 2:11:53, time: 0.818, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0110, loss_cls: 0.0802, acc: 96.9575, loss_bbox: 0.1219, loss: 0.2177
2023-02-09 20:53:49,206 - mmdet - INFO - Epoch [2][550/940]	lr: 2.000e-02, eta: 2:11:18, time: 0.821, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0105, loss_cls: 0.0858, acc: 96.8662, loss_bbox: 0.1238, loss: 0.2244
2023-02-09 20:54:30,463 - mmdet - INFO - Epoch [2][600/940]	lr: 2.000e-02, eta: 2:10:44, time: 0.825, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0107, loss_cls: 0.0826, acc: 96.9106, loss_bbox: 0.1222, loss: 0.2200
2023-02-09 20:55:11,877 - mmdet - INFO - Epoch [2][650/940]	lr: 2.000e-02, eta: 2:10:11, time: 0.828, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0100, loss_cls: 0.0801, acc: 96.9668, loss_bbox: 0.1207, loss: 0.2148
2023-02-09 20:55:52,678 - mmdet - INFO - Epoch [2][700/940]	lr: 2.000e-02, eta: 2:09:33, time: 0.816, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0044, loss_rpn_bbox: 0.0108, loss_cls: 0.0827, acc: 96.8936, loss_bbox: 0.1264, loss: 0.2244
2023-02-09 20:56:33,416 - mmdet - INFO - Epoch [2][750/940]	lr: 2.000e-02, eta: 2:08:56, time: 0.815, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0040, loss_rpn_bbox: 0.0108, loss_cls: 0.0840, acc: 96.8423, loss_bbox: 0.1295, loss: 0.2282
2023-02-09 20:57:13,511 - mmdet - INFO - Epoch [2][800/940]	lr: 2.000e-02, eta: 2:08:14, time: 0.801, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0045, loss_rpn_bbox: 0.0110, loss_cls: 0.0825, acc: 96.9099, loss_bbox: 0.1185, loss: 0.2165
2023-02-09 20:57:54,533 - mmdet - INFO - Epoch [2][850/940]	lr: 2.000e-02, eta: 2:07:37, time: 0.820, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0039, loss_rpn_bbox: 0.0110, loss_cls: 0.0822, acc: 96.8596, loss_bbox: 0.1279, loss: 0.2251
2023-02-09 20:58:35,195 - mmdet - INFO - Epoch [2][900/940]	lr: 2.000e-02, eta: 2:06:59, time: 0.814, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0035, loss_rpn_bbox: 0.0106, loss_cls: 0.0732, acc: 97.1606, loss_bbox: 0.1166, loss: 0.2038
2023-02-09 20:59:07,757 - mmdet - INFO - Saving checkpoint at 2 epochs
2023-02-09 21:02:02,796 - mmdet - INFO - 
+-------------+------+-------+--------+-------+
| class       | gts  | dets  | recall | ap    |
+-------------+------+-------+--------+-------+
| aeroplane   | 285  | 633   | 0.930  | 0.867 |
| bicycle     | 337  | 1316  | 0.961  | 0.878 |
| bird        | 459  | 915   | 0.885  | 0.782 |
| boat        | 263  | 1190  | 0.897  | 0.705 |
| bottle      | 469  | 1062  | 0.859  | 0.743 |
| bus         | 213  | 549   | 0.953  | 0.865 |
| car         | 1201 | 2118  | 0.962  | 0.896 |
| cat         | 358  | 781   | 0.964  | 0.836 |
| chair       | 756  | 5786  | 0.914  | 0.719 |
| cow         | 244  | 522   | 0.914  | 0.842 |
| diningtable | 206  | 1381  | 0.976  | 0.764 |
| dog         | 489  | 1462  | 0.967  | 0.832 |
| horse       | 348  | 1446  | 0.968  | 0.879 |
| motorbike   | 325  | 1172  | 0.966  | 0.868 |
| person      | 4528 | 10969 | 0.963  | 0.881 |
| pottedplant | 480  | 1286  | 0.758  | 0.537 |
| sheep       | 242  | 696   | 0.955  | 0.844 |
| sofa        | 239  | 1359  | 0.967  | 0.793 |
| train       | 282  | 542   | 0.918  | 0.850 |
| tvmonitor   | 308  | 1112  | 0.932  | 0.823 |
+-------------+------+-------+--------+-------+
| mAP         |      |       |        | 0.810 |
+-------------+------+-------+--------+-------+
2023-02-09 21:02:02,844 - mmdet - INFO - Exp name: mask_rcnn_r50_fpn_1x_voc07.py
2023-02-09 21:02:02,844 - mmdet - INFO - Epoch(val) [2][4952]	mAP: 0.8101, AP50: 0.8100
2023-02-09 21:03:08,469 - mmdet - INFO - Epoch [3][50/940]	lr: 2.000e-02, eta: 2:05:11, time: 1.308, data_time: 0.114, memory: 14584, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0094, loss_cls: 0.0671, acc: 97.4077, loss_bbox: 0.1124, loss: 0.1919
2023-02-09 21:03:49,392 - mmdet - INFO - Epoch [3][100/940]	lr: 2.000e-02, eta: 2:04:34, time: 0.819, data_time: 0.020, memory: 14584, loss_rpn_cls: 0.0033, loss_rpn_bbox: 0.0100, loss_cls: 0.0705, acc: 97.2900, loss_bbox: 0.1164, loss: 0.2002
2023-02-09 21:04:30,450 - mmdet - INFO - Epoch [3][150/940]	lr: 2.000e-02, eta: 2:03:58, time: 0.822, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0029, loss_rpn_bbox: 0.0097, loss_cls: 0.0672, acc: 97.4111, loss_bbox: 0.1095, loss: 0.1893
2023-02-09 21:05:11,491 - mmdet - INFO - Epoch [3][200/940]	lr: 2.000e-02, eta: 2:03:22, time: 0.821, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0031, loss_rpn_bbox: 0.0090, loss_cls: 0.0632, acc: 97.5464, loss_bbox: 0.1055, loss: 0.1809
2023-02-09 21:05:52,671 - mmdet - INFO - Epoch [3][250/940]	lr: 2.000e-02, eta: 2:02:46, time: 0.824, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0094, loss_cls: 0.0612, acc: 97.6287, loss_bbox: 0.1044, loss: 0.1777
2023-02-09 21:06:54,002 - mmdet - INFO - Epoch [3][300/940]	lr: 2.000e-02, eta: 2:03:33, time: 1.227, data_time: 0.030, memory: 14584, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0095, loss_cls: 0.0640, acc: 97.5339, loss_bbox: 0.1086, loss: 0.1852
2023-02-09 21:08:16,525 - mmdet - INFO - Epoch [3][350/940]	lr: 2.000e-02, eta: 2:05:42, time: 1.650, data_time: 0.045, memory: 14584, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0097, loss_cls: 0.0648, acc: 97.5034, loss_bbox: 0.1078, loss: 0.1851
2023-02-09 21:08:57,753 - mmdet - INFO - Epoch [3][400/940]	lr: 2.000e-02, eta: 2:04:59, time: 0.824, data_time: 0.020, memory: 14584, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0101, loss_cls: 0.0629, acc: 97.5767, loss_bbox: 0.1037, loss: 0.1797
2023-02-09 21:09:38,945 - mmdet - INFO - Epoch [3][450/940]	lr: 2.000e-02, eta: 2:04:15, time: 0.825, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0032, loss_rpn_bbox: 0.0095, loss_cls: 0.0663, acc: 97.4307, loss_bbox: 0.1115, loss: 0.1904
2023-02-09 21:10:20,126 - mmdet - INFO - Epoch [3][500/940]	lr: 2.000e-02, eta: 2:03:32, time: 0.824, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0099, loss_cls: 0.0688, acc: 97.3608, loss_bbox: 0.1138, loss: 0.1955
2023-02-09 21:11:01,105 - mmdet - INFO - Epoch [3][550/940]	lr: 2.000e-02, eta: 2:02:48, time: 0.820, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0030, loss_rpn_bbox: 0.0100, loss_cls: 0.0642, acc: 97.5283, loss_bbox: 0.1075, loss: 0.1846
2023-02-09 21:11:42,292 - mmdet - INFO - Epoch [3][600/940]	lr: 2.000e-02, eta: 2:02:05, time: 0.824, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0095, loss_cls: 0.0668, acc: 97.3884, loss_bbox: 0.1112, loss: 0.1904
2023-02-09 21:12:23,536 - mmdet - INFO - Epoch [3][650/940]	lr: 2.000e-02, eta: 2:01:22, time: 0.824, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0090, loss_cls: 0.0632, acc: 97.5803, loss_bbox: 0.1053, loss: 0.1802
2023-02-09 21:13:04,529 - mmdet - INFO - Epoch [3][700/940]	lr: 2.000e-02, eta: 2:00:38, time: 0.821, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0095, loss_cls: 0.0660, acc: 97.4187, loss_bbox: 0.1087, loss: 0.1869
2023-02-09 21:13:45,499 - mmdet - INFO - Epoch [3][750/940]	lr: 2.000e-02, eta: 1:59:54, time: 0.819, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0101, loss_cls: 0.0625, acc: 97.5610, loss_bbox: 0.1053, loss: 0.1804
2023-02-09 21:14:27,227 - mmdet - INFO - Epoch [3][800/940]	lr: 2.000e-02, eta: 1:59:13, time: 0.835, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0028, loss_rpn_bbox: 0.0095, loss_cls: 0.0611, acc: 97.6016, loss_bbox: 0.1036, loss: 0.1770
2023-02-09 21:15:08,175 - mmdet - INFO - Epoch [3][850/940]	lr: 2.000e-02, eta: 1:58:30, time: 0.818, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0025, loss_rpn_bbox: 0.0099, loss_cls: 0.0618, acc: 97.6052, loss_bbox: 0.1074, loss: 0.1816
2023-02-09 21:15:49,205 - mmdet - INFO - Epoch [3][900/940]	lr: 2.000e-02, eta: 1:57:46, time: 0.821, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0027, loss_rpn_bbox: 0.0091, loss_cls: 0.0586, acc: 97.7478, loss_bbox: 0.1006, loss: 0.1709
2023-02-09 21:16:21,842 - mmdet - INFO - Saving checkpoint at 3 epochs
2023-02-09 21:18:53,363 - mmdet - INFO - 
+-------------+------+------+--------+-------+
| class       | gts  | dets | recall | ap    |
+-------------+------+------+--------+-------+
| aeroplane   | 285  | 482  | 0.891  | 0.799 |
| bicycle     | 337  | 753  | 0.917  | 0.850 |
| bird        | 459  | 1256 | 0.885  | 0.779 |
| boat        | 263  | 855  | 0.856  | 0.709 |
| bottle      | 469  | 904  | 0.827  | 0.750 |
| bus         | 213  | 443  | 0.930  | 0.871 |
| car         | 1201 | 1870 | 0.933  | 0.888 |
| cat         | 358  | 614  | 0.916  | 0.817 |
| chair       | 756  | 2896 | 0.857  | 0.669 |
| cow         | 244  | 623  | 0.930  | 0.853 |
| diningtable | 206  | 826  | 0.903  | 0.774 |
| dog         | 489  | 1574 | 0.971  | 0.829 |
| horse       | 348  | 675  | 0.937  | 0.881 |
| motorbike   | 325  | 783  | 0.911  | 0.840 |
| person      | 4528 | 9502 | 0.953  | 0.874 |
| pottedplant | 480  | 1626 | 0.796  | 0.549 |
| sheep       | 242  | 703  | 0.934  | 0.800 |
| sofa        | 239  | 944  | 0.941  | 0.819 |
| train       | 282  | 440  | 0.894  | 0.791 |
| tvmonitor   | 308  | 579  | 0.867  | 0.797 |
+-------------+------+------+--------+-------+
| mAP         |      |      |        | 0.797 |
+-------------+------+------+--------+-------+
2023-02-09 21:18:53,394 - mmdet - INFO - Exp name: mask_rcnn_r50_fpn_1x_voc07.py
2023-02-09 21:18:53,394 - mmdet - INFO - Epoch(val) [3][4952]	mAP: 0.7969, AP50: 0.7970
2023-02-09 21:19:37,990 - mmdet - INFO - Epoch [4][50/940]	lr: 2.000e-02, eta: 1:55:02, time: 0.888, data_time: 0.083, memory: 14584, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0080, loss_cls: 0.0535, acc: 97.9041, loss_bbox: 0.0965, loss: 0.1604
2023-02-09 21:20:18,886 - mmdet - INFO - Epoch [4][100/940]	lr: 2.000e-02, eta: 1:54:21, time: 0.819, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0021, loss_rpn_bbox: 0.0088, loss_cls: 0.0506, acc: 98.0327, loss_bbox: 0.0919, loss: 0.1535
2023-02-09 21:21:00,582 - mmdet - INFO - Epoch [4][150/940]	lr: 2.000e-02, eta: 1:53:42, time: 0.834, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0096, loss_cls: 0.0557, acc: 97.8062, loss_bbox: 0.1000, loss: 0.1674
2023-02-09 21:21:41,740 - mmdet - INFO - Epoch [4][200/940]	lr: 2.000e-02, eta: 1:53:01, time: 0.822, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0085, loss_cls: 0.0546, acc: 97.8706, loss_bbox: 0.0973, loss: 0.1626
2023-02-09 21:22:23,201 - mmdet - INFO - Epoch [4][250/940]	lr: 2.000e-02, eta: 1:52:21, time: 0.829, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0096, loss_cls: 0.0570, acc: 97.7727, loss_bbox: 0.1005, loss: 0.1694
2023-02-09 21:23:04,222 - mmdet - INFO - Epoch [4][300/940]	lr: 2.000e-02, eta: 1:51:40, time: 0.821, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0020, loss_rpn_bbox: 0.0092, loss_cls: 0.0560, acc: 97.8250, loss_bbox: 0.0994, loss: 0.1666
2023-02-09 21:23:45,377 - mmdet - INFO - Epoch [4][350/940]	lr: 2.000e-02, eta: 1:50:59, time: 0.822, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0020, loss_rpn_bbox: 0.0093, loss_cls: 0.0523, acc: 97.9590, loss_bbox: 0.0986, loss: 0.1622
2023-02-09 21:24:26,675 - mmdet - INFO - Epoch [4][400/940]	lr: 2.000e-02, eta: 1:50:19, time: 0.827, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0019, loss_rpn_bbox: 0.0079, loss_cls: 0.0504, acc: 98.0378, loss_bbox: 0.0919, loss: 0.1520
2023-02-09 21:25:08,102 - mmdet - INFO - Epoch [4][450/940]	lr: 2.000e-02, eta: 1:49:39, time: 0.829, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0019, loss_rpn_bbox: 0.0082, loss_cls: 0.0536, acc: 97.8850, loss_bbox: 0.0962, loss: 0.1598
2023-02-09 21:25:48,911 - mmdet - INFO - Epoch [4][500/940]	lr: 2.000e-02, eta: 1:48:57, time: 0.816, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0023, loss_rpn_bbox: 0.0088, loss_cls: 0.0535, acc: 97.8826, loss_bbox: 0.0973, loss: 0.1618
2023-02-09 21:26:29,963 - mmdet - INFO - Epoch [4][550/940]	lr: 2.000e-02, eta: 1:48:16, time: 0.821, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0020, loss_rpn_bbox: 0.0095, loss_cls: 0.0514, acc: 97.9895, loss_bbox: 0.0947, loss: 0.1576
2023-02-09 21:27:11,081 - mmdet - INFO - Epoch [4][600/940]	lr: 2.000e-02, eta: 1:47:35, time: 0.822, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0019, loss_rpn_bbox: 0.0090, loss_cls: 0.0520, acc: 97.9646, loss_bbox: 0.0960, loss: 0.1589
2023-02-09 21:27:52,163 - mmdet - INFO - Epoch [4][650/940]	lr: 2.000e-02, eta: 1:46:54, time: 0.822, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0024, loss_rpn_bbox: 0.0090, loss_cls: 0.0547, acc: 97.8674, loss_bbox: 0.0976, loss: 0.1637
2023-02-09 21:28:33,030 - mmdet - INFO - Epoch [4][700/940]	lr: 2.000e-02, eta: 1:46:12, time: 0.817, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0021, loss_rpn_bbox: 0.0090, loss_cls: 0.0519, acc: 97.9392, loss_bbox: 0.0954, loss: 0.1583
2023-02-09 21:29:14,020 - mmdet - INFO - Epoch [4][750/940]	lr: 2.000e-02, eta: 1:45:31, time: 0.820, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0022, loss_rpn_bbox: 0.0090, loss_cls: 0.0527, acc: 97.9292, loss_bbox: 0.0970, loss: 0.1609
2023-02-09 21:29:55,767 - mmdet - INFO - Epoch [4][800/940]	lr: 2.000e-02, eta: 1:44:51, time: 0.834, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0021, loss_rpn_bbox: 0.0101, loss_cls: 0.0585, acc: 97.6897, loss_bbox: 0.1069, loss: 0.1775
2023-02-09 21:30:36,825 - mmdet - INFO - Epoch [4][850/940]	lr: 2.000e-02, eta: 1:44:10, time: 0.821, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0019, loss_rpn_bbox: 0.0088, loss_cls: 0.0497, acc: 98.0459, loss_bbox: 0.0926, loss: 0.1530
2023-02-09 21:31:17,726 - mmdet - INFO - Epoch [4][900/940]	lr: 2.000e-02, eta: 1:43:29, time: 0.819, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0016, loss_rpn_bbox: 0.0084, loss_cls: 0.0491, acc: 98.0627, loss_bbox: 0.0928, loss: 0.1520
2023-02-09 21:31:50,926 - mmdet - INFO - Saving checkpoint at 4 epochs
2023-02-09 21:34:05,693 - mmdet - INFO - 
+-------------+------+------+--------+-------+
| class       | gts  | dets | recall | ap    |
+-------------+------+------+--------+-------+
| aeroplane   | 285  | 679  | 0.930  | 0.886 |
| bicycle     | 337  | 602  | 0.941  | 0.876 |
| bird        | 459  | 759  | 0.847  | 0.786 |
| boat        | 263  | 713  | 0.882  | 0.692 |
| bottle      | 469  | 840  | 0.804  | 0.741 |
| bus         | 213  | 763  | 0.944  | 0.868 |
| car         | 1201 | 1971 | 0.957  | 0.892 |
| cat         | 358  | 900  | 0.944  | 0.848 |
| chair       | 756  | 2824 | 0.824  | 0.673 |
| cow         | 244  | 695  | 0.939  | 0.857 |
| diningtable | 206  | 858  | 0.913  | 0.756 |
| dog         | 489  | 1218 | 0.969  | 0.841 |
| horse       | 348  | 540  | 0.943  | 0.888 |
| motorbike   | 325  | 805  | 0.948  | 0.862 |
| person      | 4528 | 7434 | 0.933  | 0.878 |
| pottedplant | 480  | 1451 | 0.783  | 0.548 |
| sheep       | 242  | 701  | 0.938  | 0.820 |
| sofa        | 239  | 1747 | 0.962  | 0.799 |
| train       | 282  | 638  | 0.901  | 0.827 |
| tvmonitor   | 308  | 982  | 0.906  | 0.799 |
+-------------+------+------+--------+-------+
| mAP         |      |      |        | 0.807 |
+-------------+------+------+--------+-------+
2023-02-09 21:34:05,732 - mmdet - INFO - Exp name: mask_rcnn_r50_fpn_1x_voc07.py
2023-02-09 21:34:05,732 - mmdet - INFO - Epoch(val) [4][4952]	mAP: 0.8067, AP50: 0.8070
2023-02-09 21:34:50,486 - mmdet - INFO - Epoch [5][50/940]	lr: 2.000e-02, eta: 1:41:18, time: 0.892, data_time: 0.082, memory: 14584, loss_rpn_cls: 0.0016, loss_rpn_bbox: 0.0082, loss_cls: 0.0446, acc: 98.2092, loss_bbox: 0.0880, loss: 0.1424
2023-02-09 21:35:31,654 - mmdet - INFO - Epoch [5][100/940]	lr: 2.000e-02, eta: 1:40:38, time: 0.823, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0016, loss_rpn_bbox: 0.0085, loss_cls: 0.0449, acc: 98.2100, loss_bbox: 0.0860, loss: 0.1411
2023-02-09 21:36:13,020 - mmdet - INFO - Epoch [5][150/940]	lr: 2.000e-02, eta: 1:39:58, time: 0.827, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0015, loss_rpn_bbox: 0.0081, loss_cls: 0.0468, acc: 98.1609, loss_bbox: 0.0917, loss: 0.1481
2023-02-09 21:36:54,208 - mmdet - INFO - Epoch [5][200/940]	lr: 2.000e-02, eta: 1:39:19, time: 0.824, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0019, loss_rpn_bbox: 0.0081, loss_cls: 0.0446, acc: 98.2546, loss_bbox: 0.0878, loss: 0.1424
2023-02-09 21:37:35,133 - mmdet - INFO - Epoch [5][250/940]	lr: 2.000e-02, eta: 1:38:38, time: 0.819, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0016, loss_rpn_bbox: 0.0082, loss_cls: 0.0452, acc: 98.2117, loss_bbox: 0.0869, loss: 0.1419
2023-02-09 21:38:16,159 - mmdet - INFO - Epoch [5][300/940]	lr: 2.000e-02, eta: 1:37:58, time: 0.820, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0016, loss_rpn_bbox: 0.0083, loss_cls: 0.0428, acc: 98.2637, loss_bbox: 0.0833, loss: 0.1360
2023-02-09 21:38:57,260 - mmdet - INFO - Epoch [5][350/940]	lr: 2.000e-02, eta: 1:37:18, time: 0.823, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0018, loss_rpn_bbox: 0.0088, loss_cls: 0.0461, acc: 98.1907, loss_bbox: 0.0869, loss: 0.1435
2023-02-09 21:39:38,537 - mmdet - INFO - Epoch [5][400/940]	lr: 2.000e-02, eta: 1:36:38, time: 0.825, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0016, loss_rpn_bbox: 0.0084, loss_cls: 0.0482, acc: 98.0979, loss_bbox: 0.0899, loss: 0.1481
2023-02-09 21:40:19,779 - mmdet - INFO - Epoch [5][450/940]	lr: 2.000e-02, eta: 1:35:59, time: 0.825, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0016, loss_rpn_bbox: 0.0088, loss_cls: 0.0473, acc: 98.1160, loss_bbox: 0.0893, loss: 0.1470
2023-02-09 21:41:01,293 - mmdet - INFO - Epoch [5][500/940]	lr: 2.000e-02, eta: 1:35:19, time: 0.830, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0015, loss_rpn_bbox: 0.0078, loss_cls: 0.0430, acc: 98.3040, loss_bbox: 0.0836, loss: 0.1360
2023-02-09 21:41:42,534 - mmdet - INFO - Epoch [5][550/940]	lr: 2.000e-02, eta: 1:34:39, time: 0.825, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0017, loss_rpn_bbox: 0.0083, loss_cls: 0.0447, acc: 98.2483, loss_bbox: 0.0864, loss: 0.1411
2023-02-09 21:42:23,423 - mmdet - INFO - Epoch [5][600/940]	lr: 2.000e-02, eta: 1:33:59, time: 0.818, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0020, loss_rpn_bbox: 0.0083, loss_cls: 0.0470, acc: 98.1426, loss_bbox: 0.0848, loss: 0.1421
2023-02-09 21:43:05,179 - mmdet - INFO - Epoch [5][650/940]	lr: 2.000e-02, eta: 1:33:20, time: 0.835, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0019, loss_rpn_bbox: 0.0088, loss_cls: 0.0460, acc: 98.1887, loss_bbox: 0.0878, loss: 0.1446
2023-02-09 21:43:46,510 - mmdet - INFO - Epoch [5][700/940]	lr: 2.000e-02, eta: 1:32:40, time: 0.827, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0016, loss_rpn_bbox: 0.0078, loss_cls: 0.0452, acc: 98.2063, loss_bbox: 0.0883, loss: 0.1429
2023-02-09 21:44:27,790 - mmdet - INFO - Epoch [5][750/940]	lr: 2.000e-02, eta: 1:32:00, time: 0.825, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0017, loss_rpn_bbox: 0.0084, loss_cls: 0.0432, acc: 98.3044, loss_bbox: 0.0846, loss: 0.1380
2023-02-09 21:45:08,692 - mmdet - INFO - Epoch [5][800/940]	lr: 2.000e-02, eta: 1:31:19, time: 0.818, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0014, loss_rpn_bbox: 0.0080, loss_cls: 0.0426, acc: 98.3186, loss_bbox: 0.0824, loss: 0.1343
2023-02-09 21:45:50,083 - mmdet - INFO - Epoch [5][850/940]	lr: 2.000e-02, eta: 1:30:39, time: 0.828, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0014, loss_rpn_bbox: 0.0081, loss_cls: 0.0419, acc: 98.3381, loss_bbox: 0.0813, loss: 0.1327
2023-02-09 21:46:31,307 - mmdet - INFO - Epoch [5][900/940]	lr: 2.000e-02, eta: 1:29:59, time: 0.824, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0013, loss_rpn_bbox: 0.0080, loss_cls: 0.0417, acc: 98.3252, loss_bbox: 0.0831, loss: 0.1342
2023-02-09 21:47:04,491 - mmdet - INFO - Saving checkpoint at 5 epochs
2023-02-09 21:49:22,533 - mmdet - INFO - 
+-------------+------+------+--------+-------+
| class       | gts  | dets | recall | ap    |
+-------------+------+------+--------+-------+
| aeroplane   | 285  | 512  | 0.909  | 0.886 |
| bicycle     | 337  | 555  | 0.905  | 0.864 |
| bird        | 459  | 799  | 0.847  | 0.771 |
| boat        | 263  | 505  | 0.837  | 0.739 |
| bottle      | 469  | 682  | 0.791  | 0.702 |
| bus         | 213  | 340  | 0.915  | 0.861 |
| car         | 1201 | 1599 | 0.923  | 0.886 |
| cat         | 358  | 725  | 0.939  | 0.848 |
| chair       | 756  | 1336 | 0.737  | 0.647 |
| cow         | 244  | 392  | 0.885  | 0.796 |
| diningtable | 206  | 694  | 0.874  | 0.740 |
| dog         | 489  | 1044 | 0.955  | 0.840 |
| horse       | 348  | 807  | 0.945  | 0.883 |
| motorbike   | 325  | 833  | 0.920  | 0.843 |
| person      | 4528 | 6297 | 0.912  | 0.871 |
| pottedplant | 480  | 910  | 0.723  | 0.568 |
| sheep       | 242  | 361  | 0.835  | 0.763 |
| sofa        | 239  | 508  | 0.887  | 0.757 |
| train       | 282  | 442  | 0.883  | 0.795 |
| tvmonitor   | 308  | 418  | 0.821  | 0.765 |
+-------------+------+------+--------+-------+
| mAP         |      |      |        | 0.791 |
+-------------+------+------+--------+-------+
2023-02-09 21:49:22,571 - mmdet - INFO - Exp name: mask_rcnn_r50_fpn_1x_voc07.py
2023-02-09 21:49:22,571 - mmdet - INFO - Epoch(val) [5][4952]	mAP: 0.7910, AP50: 0.7910
2023-02-09 21:50:07,324 - mmdet - INFO - Epoch [6][50/940]	lr: 2.000e-02, eta: 1:28:06, time: 0.892, data_time: 0.080, memory: 14584, loss_rpn_cls: 0.0012, loss_rpn_bbox: 0.0079, loss_cls: 0.0380, acc: 98.4717, loss_bbox: 0.0800, loss: 0.1271
2023-02-09 21:50:48,828 - mmdet - INFO - Epoch [6][100/940]	lr: 2.000e-02, eta: 1:27:27, time: 0.830, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0015, loss_rpn_bbox: 0.0077, loss_cls: 0.0388, acc: 98.4368, loss_bbox: 0.0770, loss: 0.1250
2023-02-09 21:51:30,348 - mmdet - INFO - Epoch [6][150/940]	lr: 2.000e-02, eta: 1:26:48, time: 0.830, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0013, loss_rpn_bbox: 0.0080, loss_cls: 0.0399, acc: 98.4243, loss_bbox: 0.0833, loss: 0.1325
2023-02-09 21:52:11,369 - mmdet - INFO - Epoch [6][200/940]	lr: 2.000e-02, eta: 1:26:08, time: 0.821, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0014, loss_rpn_bbox: 0.0076, loss_cls: 0.0387, acc: 98.4900, loss_bbox: 0.0786, loss: 0.1263
2023-02-09 21:52:52,642 - mmdet - INFO - Epoch [6][250/940]	lr: 2.000e-02, eta: 1:25:28, time: 0.825, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0012, loss_rpn_bbox: 0.0075, loss_cls: 0.0359, acc: 98.5928, loss_bbox: 0.0745, loss: 0.1191
2023-02-09 21:53:33,814 - mmdet - INFO - Exp name: mask_rcnn_r50_fpn_1x_voc07.py
2023-02-09 21:53:33,815 - mmdet - INFO - Epoch [6][300/940]	lr: 2.000e-02, eta: 1:24:49, time: 0.823, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0017, loss_rpn_bbox: 0.0078, loss_cls: 0.0401, acc: 98.4377, loss_bbox: 0.0816, loss: 0.1312
2023-02-09 21:54:15,068 - mmdet - INFO - Epoch [6][350/940]	lr: 2.000e-02, eta: 1:24:09, time: 0.826, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0015, loss_rpn_bbox: 0.0075, loss_cls: 0.0405, acc: 98.3928, loss_bbox: 0.0763, loss: 0.1257
2023-02-09 21:54:56,140 - mmdet - INFO - Epoch [6][400/940]	lr: 2.000e-02, eta: 1:23:29, time: 0.821, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0016, loss_rpn_bbox: 0.0084, loss_cls: 0.0431, acc: 98.3069, loss_bbox: 0.0814, loss: 0.1344
2023-02-09 21:55:37,440 - mmdet - INFO - Epoch [6][450/940]	lr: 2.000e-02, eta: 1:22:50, time: 0.826, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0015, loss_rpn_bbox: 0.0075, loss_cls: 0.0396, acc: 98.4131, loss_bbox: 0.0793, loss: 0.1278
2023-02-09 21:56:18,627 - mmdet - INFO - Epoch [6][500/940]	lr: 2.000e-02, eta: 1:22:10, time: 0.824, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0015, loss_rpn_bbox: 0.0081, loss_cls: 0.0413, acc: 98.3506, loss_bbox: 0.0795, loss: 0.1304
2023-02-09 21:56:59,482 - mmdet - INFO - Epoch [6][550/940]	lr: 2.000e-02, eta: 1:21:30, time: 0.816, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0015, loss_rpn_bbox: 0.0077, loss_cls: 0.0379, acc: 98.4976, loss_bbox: 0.0778, loss: 0.1249
2023-02-09 21:57:40,779 - mmdet - INFO - Epoch [6][600/940]	lr: 2.000e-02, eta: 1:20:50, time: 0.826, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0013, loss_rpn_bbox: 0.0078, loss_cls: 0.0397, acc: 98.4182, loss_bbox: 0.0789, loss: 0.1277
2023-02-09 21:58:22,130 - mmdet - INFO - Epoch [6][650/940]	lr: 2.000e-02, eta: 1:20:10, time: 0.828, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0014, loss_rpn_bbox: 0.0077, loss_cls: 0.0400, acc: 98.4146, loss_bbox: 0.0807, loss: 0.1298
2023-02-09 21:59:03,315 - mmdet - INFO - Epoch [6][700/940]	lr: 2.000e-02, eta: 1:19:30, time: 0.824, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0012, loss_rpn_bbox: 0.0082, loss_cls: 0.0388, acc: 98.4688, loss_bbox: 0.0787, loss: 0.1269
2023-02-09 21:59:44,640 - mmdet - INFO - Epoch [6][750/940]	lr: 2.000e-02, eta: 1:18:51, time: 0.827, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0013, loss_rpn_bbox: 0.0078, loss_cls: 0.0380, acc: 98.4805, loss_bbox: 0.0779, loss: 0.1250
2023-02-09 22:00:26,044 - mmdet - INFO - Epoch [6][800/940]	lr: 2.000e-02, eta: 1:18:11, time: 0.828, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0012, loss_rpn_bbox: 0.0075, loss_cls: 0.0375, acc: 98.5034, loss_bbox: 0.0764, loss: 0.1225
2023-02-09 22:01:07,324 - mmdet - INFO - Epoch [6][850/940]	lr: 2.000e-02, eta: 1:17:31, time: 0.826, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0014, loss_rpn_bbox: 0.0079, loss_cls: 0.0403, acc: 98.4050, loss_bbox: 0.0811, loss: 0.1306
2023-02-09 22:01:48,697 - mmdet - INFO - Epoch [6][900/940]	lr: 2.000e-02, eta: 1:16:51, time: 0.827, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0014, loss_rpn_bbox: 0.0082, loss_cls: 0.0398, acc: 98.4138, loss_bbox: 0.0816, loss: 0.1310
2023-02-09 22:02:21,626 - mmdet - INFO - Saving checkpoint at 6 epochs
2023-02-09 22:04:36,291 - mmdet - INFO - 
+-------------+------+------+--------+-------+
| class       | gts  | dets | recall | ap    |
+-------------+------+------+--------+-------+
| aeroplane   | 285  | 686  | 0.919  | 0.857 |
| bicycle     | 337  | 556  | 0.914  | 0.864 |
| bird        | 459  | 769  | 0.861  | 0.779 |
| boat        | 263  | 769  | 0.852  | 0.719 |
| bottle      | 469  | 921  | 0.825  | 0.744 |
| bus         | 213  | 438  | 0.930  | 0.852 |
| car         | 1201 | 2022 | 0.947  | 0.890 |
| cat         | 358  | 672  | 0.936  | 0.833 |
| chair       | 756  | 3034 | 0.885  | 0.716 |
| cow         | 244  | 432  | 0.889  | 0.797 |
| diningtable | 206  | 1101 | 0.947  | 0.783 |
| dog         | 489  | 1388 | 0.965  | 0.848 |
| horse       | 348  | 668  | 0.943  | 0.889 |
| motorbike   | 325  | 757  | 0.914  | 0.853 |
| person      | 4528 | 6525 | 0.907  | 0.859 |
| pottedplant | 480  | 1101 | 0.752  | 0.576 |
| sheep       | 242  | 460  | 0.913  | 0.828 |
| sofa        | 239  | 980  | 0.954  | 0.808 |
| train       | 282  | 492  | 0.901  | 0.841 |
| tvmonitor   | 308  | 505  | 0.828  | 0.771 |
+-------------+------+------+--------+-------+
| mAP         |      |      |        | 0.805 |
+-------------+------+------+--------+-------+
2023-02-09 22:04:36,322 - mmdet - INFO - Exp name: mask_rcnn_r50_fpn_1x_voc07.py
2023-02-09 22:04:36,323 - mmdet - INFO - Epoch(val) [6][4952]	mAP: 0.8053, AP50: 0.8050
2023-02-09 22:05:20,709 - mmdet - INFO - Epoch [7][50/940]	lr: 2.000e-02, eta: 1:15:10, time: 0.885, data_time: 0.082, memory: 14584, loss_rpn_cls: 0.0013, loss_rpn_bbox: 0.0073, loss_cls: 0.0345, acc: 98.6199, loss_bbox: 0.0718, loss: 0.1148
2023-02-09 22:06:02,153 - mmdet - INFO - Epoch [7][100/940]	lr: 2.000e-02, eta: 1:14:31, time: 0.829, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0012, loss_rpn_bbox: 0.0075, loss_cls: 0.0354, acc: 98.6011, loss_bbox: 0.0739, loss: 0.1180
2023-02-09 22:06:43,413 - mmdet - INFO - Epoch [7][150/940]	lr: 2.000e-02, eta: 1:13:51, time: 0.825, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0013, loss_rpn_bbox: 0.0073, loss_cls: 0.0375, acc: 98.5120, loss_bbox: 0.0795, loss: 0.1256
2023-02-09 22:07:24,654 - mmdet - INFO - Epoch [7][200/940]	lr: 2.000e-02, eta: 1:13:12, time: 0.825, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0013, loss_rpn_bbox: 0.0080, loss_cls: 0.0361, acc: 98.5730, loss_bbox: 0.0744, loss: 0.1197
2023-02-09 22:08:05,874 - mmdet - INFO - Epoch [7][250/940]	lr: 2.000e-02, eta: 1:12:32, time: 0.824, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0011, loss_rpn_bbox: 0.0071, loss_cls: 0.0347, acc: 98.6169, loss_bbox: 0.0739, loss: 0.1168
2023-02-09 22:08:46,815 - mmdet - INFO - Epoch [7][300/940]	lr: 2.000e-02, eta: 1:11:52, time: 0.819, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0014, loss_rpn_bbox: 0.0081, loss_cls: 0.0371, acc: 98.5107, loss_bbox: 0.0769, loss: 0.1234
2023-02-09 22:09:28,086 - mmdet - INFO - Epoch [7][350/940]	lr: 2.000e-02, eta: 1:11:12, time: 0.826, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0011, loss_rpn_bbox: 0.0075, loss_cls: 0.0368, acc: 98.5410, loss_bbox: 0.0772, loss: 0.1226
2023-02-09 22:10:09,867 - mmdet - INFO - Epoch [7][400/940]	lr: 2.000e-02, eta: 1:10:33, time: 0.835, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0011, loss_rpn_bbox: 0.0077, loss_cls: 0.0370, acc: 98.5249, loss_bbox: 0.0754, loss: 0.1212
2023-02-09 22:10:51,151 - mmdet - INFO - Epoch [7][450/940]	lr: 2.000e-02, eta: 1:09:54, time: 0.826, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0013, loss_rpn_bbox: 0.0068, loss_cls: 0.0343, acc: 98.6216, loss_bbox: 0.0694, loss: 0.1118
2023-02-09 22:11:32,653 - mmdet - INFO - Epoch [7][500/940]	lr: 2.000e-02, eta: 1:09:14, time: 0.830, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0011, loss_rpn_bbox: 0.0069, loss_cls: 0.0325, acc: 98.7056, loss_bbox: 0.0674, loss: 0.1079
2023-02-09 22:12:14,135 - mmdet - INFO - Epoch [7][550/940]	lr: 2.000e-02, eta: 1:08:35, time: 0.829, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0010, loss_rpn_bbox: 0.0074, loss_cls: 0.0341, acc: 98.6331, loss_bbox: 0.0731, loss: 0.1156
2023-02-09 22:12:55,066 - mmdet - INFO - Epoch [7][600/940]	lr: 2.000e-02, eta: 1:07:55, time: 0.819, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0013, loss_rpn_bbox: 0.0080, loss_cls: 0.0372, acc: 98.4802, loss_bbox: 0.0770, loss: 0.1235
2023-02-09 22:13:37,935 - mmdet - INFO - Epoch [7][650/940]	lr: 2.000e-02, eta: 1:07:16, time: 0.856, data_time: 0.031, memory: 14584, loss_rpn_cls: 0.0012, loss_rpn_bbox: 0.0072, loss_cls: 0.0324, acc: 98.6819, loss_bbox: 0.0703, loss: 0.1112
2023-02-09 22:14:19,135 - mmdet - INFO - Epoch [7][700/940]	lr: 2.000e-02, eta: 1:06:36, time: 0.826, data_time: 0.020, memory: 14584, loss_rpn_cls: 0.0013, loss_rpn_bbox: 0.0076, loss_cls: 0.0362, acc: 98.5569, loss_bbox: 0.0746, loss: 0.1197
2023-02-09 22:15:00,611 - mmdet - INFO - Epoch [7][750/940]	lr: 2.000e-02, eta: 1:05:57, time: 0.829, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0013, loss_rpn_bbox: 0.0082, loss_cls: 0.0377, acc: 98.5071, loss_bbox: 0.0759, loss: 0.1231
2023-02-09 22:15:41,763 - mmdet - INFO - Epoch [7][800/940]	lr: 2.000e-02, eta: 1:05:17, time: 0.822, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0010, loss_rpn_bbox: 0.0069, loss_cls: 0.0325, acc: 98.6829, loss_bbox: 0.0689, loss: 0.1092
2023-02-09 22:16:22,892 - mmdet - INFO - Epoch [7][850/940]	lr: 2.000e-02, eta: 1:04:37, time: 0.823, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0013, loss_rpn_bbox: 0.0077, loss_cls: 0.0383, acc: 98.4736, loss_bbox: 0.0771, loss: 0.1243
2023-02-09 22:17:04,275 - mmdet - INFO - Epoch [7][900/940]	lr: 2.000e-02, eta: 1:03:57, time: 0.828, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0012, loss_rpn_bbox: 0.0069, loss_cls: 0.0349, acc: 98.6216, loss_bbox: 0.0733, loss: 0.1163
2023-02-09 22:17:37,368 - mmdet - INFO - Saving checkpoint at 7 epochs
2023-02-09 22:19:53,351 - mmdet - INFO - 
+-------------+------+------+--------+-------+
| class       | gts  | dets | recall | ap    |
+-------------+------+------+--------+-------+
| aeroplane   | 285  | 456  | 0.895  | 0.805 |
| bicycle     | 337  | 636  | 0.914  | 0.859 |
| bird        | 459  | 1149 | 0.839  | 0.754 |
| boat        | 263  | 467  | 0.798  | 0.664 |
| bottle      | 469  | 706  | 0.759  | 0.683 |
| bus         | 213  | 427  | 0.930  | 0.862 |
| car         | 1201 | 1823 | 0.938  | 0.887 |
| cat         | 358  | 877  | 0.936  | 0.825 |
| chair       | 756  | 1418 | 0.738  | 0.633 |
| cow         | 244  | 334  | 0.852  | 0.792 |
| diningtable | 206  | 444  | 0.816  | 0.726 |
| dog         | 489  | 637  | 0.832  | 0.749 |
| horse       | 348  | 546  | 0.914  | 0.871 |
| motorbike   | 325  | 604  | 0.855  | 0.779 |
| person      | 4528 | 6211 | 0.898  | 0.802 |
| pottedplant | 480  | 806  | 0.669  | 0.514 |
| sheep       | 242  | 496  | 0.855  | 0.762 |
| sofa        | 239  | 746  | 0.941  | 0.824 |
| train       | 282  | 449  | 0.883  | 0.795 |
| tvmonitor   | 308  | 596  | 0.851  | 0.764 |
+-------------+------+------+--------+-------+
| mAP         |      |      |        | 0.768 |
+-------------+------+------+--------+-------+
2023-02-09 22:19:53,392 - mmdet - INFO - Exp name: mask_rcnn_r50_fpn_1x_voc07.py
2023-02-09 22:19:53,392 - mmdet - INFO - Epoch(val) [7][4952]	mAP: 0.7675, AP50: 0.7680
2023-02-09 22:20:38,131 - mmdet - INFO - Epoch [8][50/940]	lr: 2.000e-02, eta: 1:02:24, time: 0.892, data_time: 0.080, memory: 14584, loss_rpn_cls: 0.0012, loss_rpn_bbox: 0.0072, loss_cls: 0.0349, acc: 98.6189, loss_bbox: 0.0722, loss: 0.1154
2023-02-09 22:21:19,399 - mmdet - INFO - Epoch [8][100/940]	lr: 2.000e-02, eta: 1:01:45, time: 0.825, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0011, loss_rpn_bbox: 0.0072, loss_cls: 0.0339, acc: 98.6519, loss_bbox: 0.0711, loss: 0.1133
2023-02-09 22:22:09,579 - mmdet - INFO - Epoch [8][150/940]	lr: 2.000e-02, eta: 1:01:11, time: 1.006, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0012, loss_rpn_bbox: 0.0074, loss_cls: 0.0325, acc: 98.6987, loss_bbox: 0.0709, loss: 0.1119
2023-02-09 22:22:51,781 - mmdet - INFO - Epoch [8][200/940]	lr: 2.000e-02, eta: 1:00:32, time: 0.841, data_time: 0.016, memory: 14584, loss_rpn_cls: 0.0009, loss_rpn_bbox: 0.0066, loss_cls: 0.0312, acc: 98.7373, loss_bbox: 0.0670, loss: 0.1057
2023-02-09 22:23:32,920 - mmdet - INFO - Epoch [8][250/940]	lr: 2.000e-02, eta: 0:59:52, time: 0.822, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0011, loss_rpn_bbox: 0.0068, loss_cls: 0.0319, acc: 98.7205, loss_bbox: 0.0673, loss: 0.1071
2023-02-09 22:24:14,558 - mmdet - INFO - Epoch [8][300/940]	lr: 2.000e-02, eta: 0:59:12, time: 0.833, data_time: 0.024, memory: 14584, loss_rpn_cls: 0.0011, loss_rpn_bbox: 0.0069, loss_cls: 0.0305, acc: 98.7812, loss_bbox: 0.0655, loss: 0.1041
2023-02-09 22:24:55,646 - mmdet - INFO - Epoch [8][350/940]	lr: 2.000e-02, eta: 0:58:33, time: 0.822, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0011, loss_rpn_bbox: 0.0071, loss_cls: 0.0314, acc: 98.7471, loss_bbox: 0.0682, loss: 0.1078
2023-02-09 22:25:37,458 - mmdet - INFO - Epoch [8][400/940]	lr: 2.000e-02, eta: 0:57:53, time: 0.836, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0011, loss_rpn_bbox: 0.0075, loss_cls: 0.0347, acc: 98.6084, loss_bbox: 0.0738, loss: 0.1171
2023-02-09 22:26:19,683 - mmdet - INFO - Epoch [8][450/940]	lr: 2.000e-02, eta: 0:57:14, time: 0.844, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0010, loss_rpn_bbox: 0.0067, loss_cls: 0.0312, acc: 98.7622, loss_bbox: 0.0670, loss: 0.1059
2023-02-09 22:27:01,086 - mmdet - INFO - Epoch [8][500/940]	lr: 2.000e-02, eta: 0:56:34, time: 0.828, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0011, loss_rpn_bbox: 0.0071, loss_cls: 0.0320, acc: 98.7168, loss_bbox: 0.0679, loss: 0.1080
2023-02-09 22:27:42,009 - mmdet - INFO - Epoch [8][550/940]	lr: 2.000e-02, eta: 0:55:54, time: 0.818, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0011, loss_rpn_bbox: 0.0067, loss_cls: 0.0318, acc: 98.7156, loss_bbox: 0.0668, loss: 0.1064
2023-02-09 22:28:22,730 - mmdet - INFO - Epoch [8][600/940]	lr: 2.000e-02, eta: 0:55:14, time: 0.814, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0010, loss_rpn_bbox: 0.0073, loss_cls: 0.0313, acc: 98.7407, loss_bbox: 0.0648, loss: 0.1046
2023-02-09 22:29:03,926 - mmdet - INFO - Epoch [8][650/940]	lr: 2.000e-02, eta: 0:54:34, time: 0.824, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0011, loss_rpn_bbox: 0.0072, loss_cls: 0.0323, acc: 98.7180, loss_bbox: 0.0678, loss: 0.1084
2023-02-09 22:29:44,984 - mmdet - INFO - Epoch [8][700/940]	lr: 2.000e-02, eta: 0:53:54, time: 0.821, data_time: 0.020, memory: 14584, loss_rpn_cls: 0.0010, loss_rpn_bbox: 0.0071, loss_cls: 0.0309, acc: 98.7600, loss_bbox: 0.0656, loss: 0.1046
2023-02-09 22:30:26,466 - mmdet - INFO - Epoch [8][750/940]	lr: 2.000e-02, eta: 0:53:14, time: 0.830, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0010, loss_rpn_bbox: 0.0068, loss_cls: 0.0331, acc: 98.6902, loss_bbox: 0.0710, loss: 0.1119
2023-02-09 22:31:08,107 - mmdet - INFO - Epoch [8][800/940]	lr: 2.000e-02, eta: 0:52:34, time: 0.833, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0010, loss_rpn_bbox: 0.0072, loss_cls: 0.0337, acc: 98.6653, loss_bbox: 0.0710, loss: 0.1129
2023-02-09 22:31:49,539 - mmdet - INFO - Epoch [8][850/940]	lr: 2.000e-02, eta: 0:51:54, time: 0.829, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0012, loss_rpn_bbox: 0.0072, loss_cls: 0.0330, acc: 98.6719, loss_bbox: 0.0702, loss: 0.1116
2023-02-09 22:32:31,133 - mmdet - INFO - Epoch [8][900/940]	lr: 2.000e-02, eta: 0:51:14, time: 0.831, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0011, loss_rpn_bbox: 0.0071, loss_cls: 0.0307, acc: 98.7607, loss_bbox: 0.0666, loss: 0.1055
2023-02-09 22:33:04,521 - mmdet - INFO - Saving checkpoint at 8 epochs
2023-02-09 22:35:21,820 - mmdet - INFO - 
+-------------+------+------+--------+-------+
| class       | gts  | dets | recall | ap    |
+-------------+------+------+--------+-------+
| aeroplane   | 285  | 512  | 0.898  | 0.798 |
| bicycle     | 337  | 594  | 0.902  | 0.860 |
| bird        | 459  | 705  | 0.834  | 0.783 |
| boat        | 263  | 432  | 0.753  | 0.646 |
| bottle      | 469  | 582  | 0.740  | 0.690 |
| bus         | 213  | 447  | 0.920  | 0.860 |
| car         | 1201 | 1710 | 0.924  | 0.885 |
| cat         | 358  | 591  | 0.916  | 0.830 |
| chair       | 756  | 1406 | 0.725  | 0.633 |
| cow         | 244  | 573  | 0.926  | 0.844 |
| diningtable | 206  | 536  | 0.874  | 0.729 |
| dog         | 489  | 1255 | 0.959  | 0.843 |
| horse       | 348  | 683  | 0.937  | 0.881 |
| motorbike   | 325  | 537  | 0.892  | 0.802 |
| person      | 4528 | 6767 | 0.922  | 0.875 |
| pottedplant | 480  | 636  | 0.625  | 0.512 |
| sheep       | 242  | 486  | 0.868  | 0.771 |
| sofa        | 239  | 712  | 0.946  | 0.816 |
| train       | 282  | 621  | 0.911  | 0.838 |
| tvmonitor   | 308  | 485  | 0.821  | 0.764 |
+-------------+------+------+--------+-------+
| mAP         |      |      |        | 0.783 |
+-------------+------+------+--------+-------+
2023-02-09 22:35:21,848 - mmdet - INFO - Exp name: mask_rcnn_r50_fpn_1x_voc07.py
2023-02-09 22:35:21,849 - mmdet - INFO - Epoch(val) [8][4952]	mAP: 0.7830, AP50: 0.7830
2023-02-09 22:36:06,807 - mmdet - INFO - Epoch [9][50/940]	lr: 2.000e-03, eta: 0:49:48, time: 0.896, data_time: 0.082, memory: 14584, loss_rpn_cls: 0.0009, loss_rpn_bbox: 0.0065, loss_cls: 0.0280, acc: 98.8728, loss_bbox: 0.0591, loss: 0.0945
2023-02-09 22:36:48,313 - mmdet - INFO - Epoch [9][100/940]	lr: 2.000e-03, eta: 0:49:08, time: 0.829, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0009, loss_rpn_bbox: 0.0058, loss_cls: 0.0262, acc: 98.9392, loss_bbox: 0.0552, loss: 0.0881
2023-02-09 22:37:29,842 - mmdet - INFO - Epoch [9][150/940]	lr: 2.000e-03, eta: 0:48:28, time: 0.831, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0009, loss_rpn_bbox: 0.0059, loss_cls: 0.0262, acc: 98.9409, loss_bbox: 0.0560, loss: 0.0890
2023-02-09 22:38:11,234 - mmdet - INFO - Epoch [9][200/940]	lr: 2.000e-03, eta: 0:47:48, time: 0.828, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0008, loss_rpn_bbox: 0.0057, loss_cls: 0.0255, acc: 98.9736, loss_bbox: 0.0534, loss: 0.0854
2023-02-09 22:38:52,606 - mmdet - INFO - Epoch [9][250/940]	lr: 2.000e-03, eta: 0:47:09, time: 0.827, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0008, loss_rpn_bbox: 0.0060, loss_cls: 0.0261, acc: 98.9548, loss_bbox: 0.0552, loss: 0.0881
2023-02-09 22:39:33,676 - mmdet - INFO - Epoch [9][300/940]	lr: 2.000e-03, eta: 0:46:29, time: 0.822, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0008, loss_rpn_bbox: 0.0059, loss_cls: 0.0254, acc: 98.9783, loss_bbox: 0.0539, loss: 0.0860
2023-02-09 22:40:14,536 - mmdet - INFO - Epoch [9][350/940]	lr: 2.000e-03, eta: 0:45:49, time: 0.817, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0007, loss_rpn_bbox: 0.0055, loss_cls: 0.0232, acc: 99.0510, loss_bbox: 0.0493, loss: 0.0788
2023-02-09 22:40:55,774 - mmdet - INFO - Epoch [9][400/940]	lr: 2.000e-03, eta: 0:45:09, time: 0.825, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0007, loss_rpn_bbox: 0.0062, loss_cls: 0.0261, acc: 98.9355, loss_bbox: 0.0557, loss: 0.0887
2023-02-09 22:41:37,342 - mmdet - INFO - Epoch [9][450/940]	lr: 2.000e-03, eta: 0:44:29, time: 0.831, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0008, loss_rpn_bbox: 0.0055, loss_cls: 0.0234, acc: 99.0498, loss_bbox: 0.0487, loss: 0.0783
2023-02-09 22:42:18,441 - mmdet - INFO - Epoch [9][500/940]	lr: 2.000e-03, eta: 0:43:49, time: 0.822, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0008, loss_rpn_bbox: 0.0057, loss_cls: 0.0246, acc: 99.0027, loss_bbox: 0.0518, loss: 0.0829
2023-02-09 22:42:59,661 - mmdet - INFO - Epoch [9][550/940]	lr: 2.000e-03, eta: 0:43:09, time: 0.824, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0008, loss_rpn_bbox: 0.0057, loss_cls: 0.0233, acc: 99.0554, loss_bbox: 0.0500, loss: 0.0798
2023-02-09 22:43:40,910 - mmdet - INFO - Epoch [9][600/940]	lr: 2.000e-03, eta: 0:42:29, time: 0.825, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0008, loss_rpn_bbox: 0.0061, loss_cls: 0.0252, acc: 98.9646, loss_bbox: 0.0534, loss: 0.0855
2023-02-09 22:44:22,349 - mmdet - INFO - Epoch [9][650/940]	lr: 2.000e-03, eta: 0:41:49, time: 0.828, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0007, loss_rpn_bbox: 0.0052, loss_cls: 0.0219, acc: 99.1179, loss_bbox: 0.0468, loss: 0.0746
2023-02-09 22:45:03,921 - mmdet - INFO - Epoch [9][700/940]	lr: 2.000e-03, eta: 0:41:09, time: 0.831, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0007, loss_rpn_bbox: 0.0056, loss_cls: 0.0239, acc: 99.0198, loss_bbox: 0.0507, loss: 0.0810
2023-02-09 22:45:45,327 - mmdet - INFO - Epoch [9][750/940]	lr: 2.000e-03, eta: 0:40:29, time: 0.828, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0007, loss_rpn_bbox: 0.0056, loss_cls: 0.0238, acc: 99.0317, loss_bbox: 0.0506, loss: 0.0807
2023-02-09 22:46:26,622 - mmdet - INFO - Epoch [9][800/940]	lr: 2.000e-03, eta: 0:39:49, time: 0.827, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0052, loss_cls: 0.0228, acc: 99.0918, loss_bbox: 0.0481, loss: 0.0767
2023-02-09 22:47:07,914 - mmdet - INFO - Epoch [9][850/940]	lr: 2.000e-03, eta: 0:39:09, time: 0.826, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0007, loss_rpn_bbox: 0.0054, loss_cls: 0.0231, acc: 99.0654, loss_bbox: 0.0487, loss: 0.0779
2023-02-09 22:47:49,090 - mmdet - INFO - Epoch [9][900/940]	lr: 2.000e-03, eta: 0:38:29, time: 0.823, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0007, loss_rpn_bbox: 0.0053, loss_cls: 0.0228, acc: 99.0872, loss_bbox: 0.0480, loss: 0.0768
2023-02-09 22:48:21,990 - mmdet - INFO - Saving checkpoint at 9 epochs
2023-02-09 22:50:39,067 - mmdet - INFO - 
+-------------+------+------+--------+-------+
| class       | gts  | dets | recall | ap    |
+-------------+------+------+--------+-------+
| aeroplane   | 285  | 406  | 0.891  | 0.813 |
| bicycle     | 337  | 455  | 0.908  | 0.882 |
| bird        | 459  | 630  | 0.826  | 0.787 |
| boat        | 263  | 476  | 0.817  | 0.728 |
| bottle      | 469  | 597  | 0.761  | 0.692 |
| bus         | 213  | 359  | 0.915  | 0.874 |
| car         | 1201 | 1542 | 0.918  | 0.888 |
| cat         | 358  | 562  | 0.916  | 0.853 |
| chair       | 756  | 1284 | 0.735  | 0.643 |
| cow         | 244  | 425  | 0.902  | 0.858 |
| diningtable | 206  | 483  | 0.864  | 0.743 |
| dog         | 489  | 907  | 0.947  | 0.853 |
| horse       | 348  | 525  | 0.934  | 0.891 |
| motorbike   | 325  | 495  | 0.874  | 0.803 |
| person      | 4528 | 5727 | 0.903  | 0.876 |
| pottedplant | 480  | 668  | 0.671  | 0.536 |
| sheep       | 242  | 401  | 0.876  | 0.778 |
| sofa        | 239  | 546  | 0.921  | 0.818 |
| train       | 282  | 433  | 0.901  | 0.852 |
| tvmonitor   | 308  | 465  | 0.838  | 0.779 |
+-------------+------+------+--------+-------+
| mAP         |      |      |        | 0.797 |
+-------------+------+------+--------+-------+
2023-02-09 22:50:39,105 - mmdet - INFO - Exp name: mask_rcnn_r50_fpn_1x_voc07.py
2023-02-09 22:50:39,106 - mmdet - INFO - Epoch(val) [9][4952]	mAP: 0.7974, AP50: 0.7970
2023-02-09 22:51:25,078 - mmdet - INFO - Epoch [10][50/940]	lr: 2.000e-03, eta: 0:37:08, time: 0.917, data_time: 0.085, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0051, loss_cls: 0.0215, acc: 99.1138, loss_bbox: 0.0442, loss: 0.0714
2023-02-09 22:52:06,270 - mmdet - INFO - Epoch [10][100/940]	lr: 2.000e-03, eta: 0:36:28, time: 0.824, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0055, loss_cls: 0.0228, acc: 99.0781, loss_bbox: 0.0485, loss: 0.0774
2023-02-09 22:52:47,891 - mmdet - INFO - Epoch [10][150/940]	lr: 2.000e-03, eta: 0:35:48, time: 0.832, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0007, loss_rpn_bbox: 0.0054, loss_cls: 0.0214, acc: 99.1409, loss_bbox: 0.0443, loss: 0.0717
2023-02-09 22:53:29,004 - mmdet - INFO - Epoch [10][200/940]	lr: 2.000e-03, eta: 0:35:08, time: 0.822, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0005, loss_rpn_bbox: 0.0050, loss_cls: 0.0210, acc: 99.1455, loss_bbox: 0.0441, loss: 0.0706
2023-02-09 22:54:10,093 - mmdet - INFO - Epoch [10][250/940]	lr: 2.000e-03, eta: 0:34:28, time: 0.822, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0059, loss_cls: 0.0238, acc: 99.0181, loss_bbox: 0.0506, loss: 0.0809
2023-02-09 22:54:51,103 - mmdet - INFO - Epoch [10][300/940]	lr: 2.000e-03, eta: 0:33:48, time: 0.820, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0007, loss_rpn_bbox: 0.0053, loss_cls: 0.0212, acc: 99.1360, loss_bbox: 0.0441, loss: 0.0713
2023-02-09 22:55:32,455 - mmdet - INFO - Epoch [10][350/940]	lr: 2.000e-03, eta: 0:33:08, time: 0.828, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0056, loss_cls: 0.0224, acc: 99.0847, loss_bbox: 0.0483, loss: 0.0768
2023-02-09 22:56:13,843 - mmdet - INFO - Epoch [10][400/940]	lr: 2.000e-03, eta: 0:32:28, time: 0.828, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0007, loss_rpn_bbox: 0.0052, loss_cls: 0.0226, acc: 99.0801, loss_bbox: 0.0470, loss: 0.0755
2023-02-09 22:56:55,176 - mmdet - INFO - Epoch [10][450/940]	lr: 2.000e-03, eta: 0:31:48, time: 0.827, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0053, loss_cls: 0.0225, acc: 99.0947, loss_bbox: 0.0475, loss: 0.0759
2023-02-09 22:57:36,436 - mmdet - INFO - Epoch [10][500/940]	lr: 2.000e-03, eta: 0:31:08, time: 0.825, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0052, loss_cls: 0.0211, acc: 99.1592, loss_bbox: 0.0448, loss: 0.0717
2023-02-09 22:58:17,583 - mmdet - INFO - Epoch [10][550/940]	lr: 2.000e-03, eta: 0:30:28, time: 0.822, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0007, loss_rpn_bbox: 0.0055, loss_cls: 0.0232, acc: 99.0483, loss_bbox: 0.0482, loss: 0.0776
2023-02-09 22:58:58,730 - mmdet - INFO - Epoch [10][600/940]	lr: 2.000e-03, eta: 0:29:48, time: 0.823, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0052, loss_cls: 0.0223, acc: 99.0945, loss_bbox: 0.0468, loss: 0.0748
2023-02-09 22:59:39,587 - mmdet - INFO - Epoch [10][650/940]	lr: 2.000e-03, eta: 0:29:08, time: 0.817, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0007, loss_rpn_bbox: 0.0056, loss_cls: 0.0226, acc: 99.0696, loss_bbox: 0.0475, loss: 0.0765
2023-02-09 23:00:21,278 - mmdet - INFO - Epoch [10][700/940]	lr: 2.000e-03, eta: 0:28:28, time: 0.835, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0005, loss_rpn_bbox: 0.0057, loss_cls: 0.0231, acc: 99.0579, loss_bbox: 0.0478, loss: 0.0771
2023-02-09 23:01:03,198 - mmdet - INFO - Epoch [10][750/940]	lr: 2.000e-03, eta: 0:27:48, time: 0.838, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0053, loss_cls: 0.0215, acc: 99.1169, loss_bbox: 0.0449, loss: 0.0722
2023-02-09 23:01:44,793 - mmdet - INFO - Epoch [10][800/940]	lr: 2.000e-03, eta: 0:27:08, time: 0.832, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0054, loss_cls: 0.0216, acc: 99.1213, loss_bbox: 0.0455, loss: 0.0731
2023-02-09 23:02:26,046 - mmdet - INFO - Epoch [10][850/940]	lr: 2.000e-03, eta: 0:26:28, time: 0.824, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0052, loss_cls: 0.0218, acc: 99.1060, loss_bbox: 0.0457, loss: 0.0733
2023-02-09 23:03:07,186 - mmdet - INFO - Epoch [10][900/940]	lr: 2.000e-03, eta: 0:25:48, time: 0.823, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0051, loss_cls: 0.0207, acc: 99.1680, loss_bbox: 0.0450, loss: 0.0714
2023-02-09 23:03:40,193 - mmdet - INFO - Saving checkpoint at 10 epochs
2023-02-09 23:05:55,761 - mmdet - INFO - 
+-------------+------+------+--------+-------+
| class       | gts  | dets | recall | ap    |
+-------------+------+------+--------+-------+
| aeroplane   | 285  | 390  | 0.898  | 0.811 |
| bicycle     | 337  | 461  | 0.905  | 0.875 |
| bird        | 459  | 625  | 0.834  | 0.790 |
| boat        | 263  | 517  | 0.840  | 0.745 |
| bottle      | 469  | 570  | 0.753  | 0.694 |
| bus         | 213  | 357  | 0.920  | 0.877 |
| car         | 1201 | 1528 | 0.921  | 0.888 |
| cat         | 358  | 544  | 0.913  | 0.851 |
| chair       | 756  | 1234 | 0.726  | 0.638 |
| cow         | 244  | 421  | 0.902  | 0.859 |
| diningtable | 206  | 475  | 0.835  | 0.741 |
| dog         | 489  | 885  | 0.945  | 0.853 |
| horse       | 348  | 531  | 0.940  | 0.893 |
| motorbike   | 325  | 473  | 0.883  | 0.801 |
| person      | 4528 | 5668 | 0.902  | 0.875 |
| pottedplant | 480  | 660  | 0.665  | 0.535 |
| sheep       | 242  | 382  | 0.872  | 0.775 |
| sofa        | 239  | 613  | 0.937  | 0.825 |
| train       | 282  | 423  | 0.890  | 0.793 |
| tvmonitor   | 308  | 453  | 0.838  | 0.778 |
+-------------+------+------+--------+-------+
| mAP         |      |      |        | 0.795 |
+-------------+------+------+--------+-------+
2023-02-09 23:05:55,799 - mmdet - INFO - Exp name: mask_rcnn_r50_fpn_1x_voc07.py
2023-02-09 23:05:55,800 - mmdet - INFO - Epoch(val) [10][4952]	mAP: 0.7948, AP50: 0.7950
2023-02-09 23:06:41,047 - mmdet - INFO - Epoch [11][50/940]	lr: 2.000e-03, eta: 0:24:30, time: 0.902, data_time: 0.082, memory: 14584, loss_rpn_cls: 0.0005, loss_rpn_bbox: 0.0058, loss_cls: 0.0213, acc: 99.1335, loss_bbox: 0.0462, loss: 0.0738
2023-02-09 23:07:22,307 - mmdet - INFO - Epoch [11][100/940]	lr: 2.000e-03, eta: 0:23:50, time: 0.825, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0053, loss_cls: 0.0209, acc: 99.1499, loss_bbox: 0.0443, loss: 0.0711
2023-02-09 23:08:03,183 - mmdet - INFO - Epoch [11][150/940]	lr: 2.000e-03, eta: 0:23:10, time: 0.817, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0005, loss_rpn_bbox: 0.0052, loss_cls: 0.0204, acc: 99.1780, loss_bbox: 0.0431, loss: 0.0693
2023-02-09 23:08:44,385 - mmdet - INFO - Epoch [11][200/940]	lr: 2.000e-03, eta: 0:22:30, time: 0.824, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0005, loss_rpn_bbox: 0.0054, loss_cls: 0.0218, acc: 99.1096, loss_bbox: 0.0461, loss: 0.0738
2023-02-09 23:09:25,651 - mmdet - INFO - Epoch [11][250/940]	lr: 2.000e-03, eta: 0:21:50, time: 0.825, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0050, loss_cls: 0.0208, acc: 99.1514, loss_bbox: 0.0440, loss: 0.0705
2023-02-09 23:10:06,993 - mmdet - INFO - Epoch [11][300/940]	lr: 2.000e-03, eta: 0:21:10, time: 0.827, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0048, loss_cls: 0.0193, acc: 99.2227, loss_bbox: 0.0415, loss: 0.0663
2023-02-09 23:10:48,464 - mmdet - INFO - Epoch [11][350/940]	lr: 2.000e-03, eta: 0:20:30, time: 0.829, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0005, loss_rpn_bbox: 0.0049, loss_cls: 0.0198, acc: 99.1980, loss_bbox: 0.0410, loss: 0.0661
2023-02-09 23:11:29,687 - mmdet - INFO - Epoch [11][400/940]	lr: 2.000e-03, eta: 0:19:50, time: 0.824, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0055, loss_cls: 0.0207, acc: 99.1548, loss_bbox: 0.0442, loss: 0.0711
2023-02-09 23:12:10,841 - mmdet - INFO - Epoch [11][450/940]	lr: 2.000e-03, eta: 0:19:10, time: 0.822, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0005, loss_rpn_bbox: 0.0054, loss_cls: 0.0222, acc: 99.0952, loss_bbox: 0.0448, loss: 0.0729
2023-02-09 23:12:52,022 - mmdet - INFO - Epoch [11][500/940]	lr: 2.000e-03, eta: 0:18:30, time: 0.824, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0047, loss_cls: 0.0197, acc: 99.2095, loss_bbox: 0.0415, loss: 0.0664
2023-02-09 23:13:33,298 - mmdet - INFO - Epoch [11][550/940]	lr: 2.000e-03, eta: 0:17:49, time: 0.826, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0051, loss_cls: 0.0199, acc: 99.2036, loss_bbox: 0.0426, loss: 0.0682
2023-02-09 23:14:14,939 - mmdet - INFO - Exp name: mask_rcnn_r50_fpn_1x_voc07.py
2023-02-09 23:14:14,939 - mmdet - INFO - Epoch [11][600/940]	lr: 2.000e-03, eta: 0:17:09, time: 0.833, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0051, loss_cls: 0.0209, acc: 99.1560, loss_bbox: 0.0423, loss: 0.0688
2023-02-09 23:14:56,425 - mmdet - INFO - Epoch [11][650/940]	lr: 2.000e-03, eta: 0:16:29, time: 0.830, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0051, loss_cls: 0.0203, acc: 99.1797, loss_bbox: 0.0423, loss: 0.0683
2023-02-09 23:15:37,548 - mmdet - INFO - Epoch [11][700/940]	lr: 2.000e-03, eta: 0:15:49, time: 0.822, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0052, loss_cls: 0.0210, acc: 99.1443, loss_bbox: 0.0435, loss: 0.0703
2023-02-09 23:16:18,721 - mmdet - INFO - Epoch [11][750/940]	lr: 2.000e-03, eta: 0:15:09, time: 0.823, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0050, loss_cls: 0.0193, acc: 99.2161, loss_bbox: 0.0412, loss: 0.0662
2023-02-09 23:17:00,302 - mmdet - INFO - Epoch [11][800/940]	lr: 2.000e-03, eta: 0:14:29, time: 0.831, data_time: 0.018, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0051, loss_cls: 0.0200, acc: 99.1990, loss_bbox: 0.0426, loss: 0.0684
2023-02-09 23:17:41,537 - mmdet - INFO - Epoch [11][850/940]	lr: 2.000e-03, eta: 0:13:49, time: 0.825, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0052, loss_cls: 0.0210, acc: 99.1499, loss_bbox: 0.0438, loss: 0.0707
2023-02-09 23:18:25,010 - mmdet - INFO - Epoch [11][900/940]	lr: 2.000e-03, eta: 0:13:09, time: 0.869, data_time: 0.023, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0054, loss_cls: 0.0202, acc: 99.1814, loss_bbox: 0.0439, loss: 0.0701
2023-02-09 23:18:58,137 - mmdet - INFO - Saving checkpoint at 11 epochs
2023-02-09 23:21:13,466 - mmdet - INFO - 
+-------------+------+------+--------+-------+
| class       | gts  | dets | recall | ap    |
+-------------+------+------+--------+-------+
| aeroplane   | 285  | 385  | 0.888  | 0.810 |
| bicycle     | 337  | 447  | 0.893  | 0.811 |
| bird        | 459  | 614  | 0.834  | 0.785 |
| boat        | 263  | 478  | 0.833  | 0.736 |
| bottle      | 469  | 564  | 0.753  | 0.691 |
| bus         | 213  | 348  | 0.915  | 0.874 |
| car         | 1201 | 1525 | 0.918  | 0.889 |
| cat         | 358  | 548  | 0.911  | 0.854 |
| chair       | 756  | 1208 | 0.716  | 0.632 |
| cow         | 244  | 420  | 0.906  | 0.857 |
| diningtable | 206  | 456  | 0.835  | 0.738 |
| dog         | 489  | 908  | 0.945  | 0.852 |
| horse       | 348  | 513  | 0.934  | 0.892 |
| motorbike   | 325  | 481  | 0.877  | 0.799 |
| person      | 4528 | 5529 | 0.898  | 0.806 |
| pottedplant | 480  | 643  | 0.665  | 0.532 |
| sheep       | 242  | 377  | 0.876  | 0.777 |
| sofa        | 239  | 618  | 0.929  | 0.817 |
| train       | 282  | 427  | 0.890  | 0.794 |
| tvmonitor   | 308  | 439  | 0.834  | 0.775 |
+-------------+------+------+--------+-------+
| mAP         |      |      |        | 0.786 |
+-------------+------+------+--------+-------+
2023-02-09 23:21:13,504 - mmdet - INFO - Exp name: mask_rcnn_r50_fpn_1x_voc07.py
2023-02-09 23:21:13,504 - mmdet - INFO - Epoch(val) [11][4952]	mAP: 0.7861, AP50: 0.7860
2023-02-09 23:21:58,562 - mmdet - INFO - Epoch [12][50/940]	lr: 2.000e-04, eta: 0:11:54, time: 0.897, data_time: 0.084, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0055, loss_cls: 0.0201, acc: 99.2002, loss_bbox: 0.0417, loss: 0.0680
2023-02-09 23:22:39,896 - mmdet - INFO - Epoch [12][100/940]	lr: 2.000e-04, eta: 0:11:14, time: 0.827, data_time: 0.020, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0047, loss_cls: 0.0195, acc: 99.2097, loss_bbox: 0.0393, loss: 0.0641
2023-02-09 23:23:21,261 - mmdet - INFO - Epoch [12][150/940]	lr: 2.000e-04, eta: 0:10:34, time: 0.828, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0005, loss_rpn_bbox: 0.0050, loss_cls: 0.0194, acc: 99.2188, loss_bbox: 0.0407, loss: 0.0655
2023-02-09 23:24:02,754 - mmdet - INFO - Epoch [12][200/940]	lr: 2.000e-04, eta: 0:09:54, time: 0.829, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0053, loss_cls: 0.0204, acc: 99.1641, loss_bbox: 0.0433, loss: 0.0696
2023-02-09 23:24:44,153 - mmdet - INFO - Epoch [12][250/940]	lr: 2.000e-04, eta: 0:09:14, time: 0.829, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0005, loss_rpn_bbox: 0.0052, loss_cls: 0.0201, acc: 99.1931, loss_bbox: 0.0417, loss: 0.0675
2023-02-09 23:25:25,765 - mmdet - INFO - Epoch [12][300/940]	lr: 2.000e-04, eta: 0:08:34, time: 0.832, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0051, loss_cls: 0.0204, acc: 99.1704, loss_bbox: 0.0425, loss: 0.0686
2023-02-09 23:26:07,230 - mmdet - INFO - Epoch [12][350/940]	lr: 2.000e-04, eta: 0:07:54, time: 0.830, data_time: 0.020, memory: 14584, loss_rpn_cls: 0.0005, loss_rpn_bbox: 0.0053, loss_cls: 0.0221, acc: 99.0994, loss_bbox: 0.0452, loss: 0.0731
2023-02-09 23:26:48,517 - mmdet - INFO - Epoch [12][400/940]	lr: 2.000e-04, eta: 0:07:13, time: 0.826, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0005, loss_rpn_bbox: 0.0047, loss_cls: 0.0190, acc: 99.2358, loss_bbox: 0.0390, loss: 0.0632
2023-02-09 23:27:30,139 - mmdet - INFO - Epoch [12][450/940]	lr: 2.000e-04, eta: 0:06:33, time: 0.832, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0005, loss_rpn_bbox: 0.0052, loss_cls: 0.0207, acc: 99.1709, loss_bbox: 0.0426, loss: 0.0690
2023-02-09 23:28:11,148 - mmdet - INFO - Epoch [12][500/940]	lr: 2.000e-04, eta: 0:05:53, time: 0.821, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0005, loss_rpn_bbox: 0.0053, loss_cls: 0.0197, acc: 99.1951, loss_bbox: 0.0408, loss: 0.0662
2023-02-09 23:28:52,469 - mmdet - INFO - Epoch [12][550/940]	lr: 2.000e-04, eta: 0:05:13, time: 0.826, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0005, loss_rpn_bbox: 0.0051, loss_cls: 0.0199, acc: 99.2068, loss_bbox: 0.0413, loss: 0.0668
2023-02-09 23:29:33,536 - mmdet - INFO - Epoch [12][600/940]	lr: 2.000e-04, eta: 0:04:33, time: 0.821, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0048, loss_cls: 0.0195, acc: 99.2234, loss_bbox: 0.0410, loss: 0.0660
2023-02-09 23:30:14,489 - mmdet - INFO - Epoch [12][650/940]	lr: 2.000e-04, eta: 0:03:53, time: 0.819, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0005, loss_rpn_bbox: 0.0051, loss_cls: 0.0197, acc: 99.2146, loss_bbox: 0.0416, loss: 0.0670
2023-02-09 23:30:55,403 - mmdet - INFO - Epoch [12][700/940]	lr: 2.000e-04, eta: 0:03:12, time: 0.819, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0005, loss_rpn_bbox: 0.0049, loss_cls: 0.0190, acc: 99.2366, loss_bbox: 0.0400, loss: 0.0644
2023-02-09 23:31:37,210 - mmdet - INFO - Epoch [12][750/940]	lr: 2.000e-04, eta: 0:02:32, time: 0.836, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0050, loss_cls: 0.0197, acc: 99.1870, loss_bbox: 0.0407, loss: 0.0660
2023-02-09 23:32:18,456 - mmdet - INFO - Epoch [12][800/940]	lr: 2.000e-04, eta: 0:01:52, time: 0.824, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0005, loss_rpn_bbox: 0.0048, loss_cls: 0.0199, acc: 99.1865, loss_bbox: 0.0412, loss: 0.0664
2023-02-09 23:32:59,794 - mmdet - INFO - Epoch [12][850/940]	lr: 2.000e-04, eta: 0:01:12, time: 0.827, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0006, loss_rpn_bbox: 0.0050, loss_cls: 0.0201, acc: 99.1904, loss_bbox: 0.0418, loss: 0.0675
2023-02-09 23:33:41,345 - mmdet - INFO - Epoch [12][900/940]	lr: 2.000e-04, eta: 0:00:32, time: 0.831, data_time: 0.019, memory: 14584, loss_rpn_cls: 0.0005, loss_rpn_bbox: 0.0048, loss_cls: 0.0190, acc: 99.2256, loss_bbox: 0.0388, loss: 0.0631
2023-02-09 23:34:13,958 - mmdet - INFO - Saving checkpoint at 12 epochs
2023-02-09 23:36:30,850 - mmdet - INFO - 
+-------------+------+------+--------+-------+
| class       | gts  | dets | recall | ap    |
+-------------+------+------+--------+-------+
| aeroplane   | 285  | 382  | 0.884  | 0.810 |
| bicycle     | 337  | 449  | 0.899  | 0.812 |
| bird        | 459  | 627  | 0.837  | 0.787 |
| boat        | 263  | 469  | 0.833  | 0.735 |
| bottle      | 469  | 573  | 0.751  | 0.693 |
| bus         | 213  | 348  | 0.915  | 0.876 |
| car         | 1201 | 1497 | 0.917  | 0.888 |
| cat         | 358  | 538  | 0.913  | 0.857 |
| chair       | 756  | 1229 | 0.717  | 0.635 |
| cow         | 244  | 417  | 0.902  | 0.859 |
| diningtable | 206  | 441  | 0.825  | 0.734 |
| dog         | 489  | 905  | 0.949  | 0.855 |
| horse       | 348  | 512  | 0.940  | 0.892 |
| motorbike   | 325  | 478  | 0.880  | 0.799 |
| person      | 4528 | 5568 | 0.900  | 0.805 |
| pottedplant | 480  | 641  | 0.665  | 0.535 |
| sheep       | 242  | 379  | 0.880  | 0.776 |
| sofa        | 239  | 581  | 0.933  | 0.819 |
| train       | 282  | 424  | 0.894  | 0.794 |
| tvmonitor   | 308  | 426  | 0.834  | 0.774 |
+-------------+------+------+--------+-------+
| mAP         |      |      |        | 0.787 |
+-------------+------+------+--------+-------+
2023-02-09 23:36:30,884 - mmdet - INFO - Exp name: mask_rcnn_r50_fpn_1x_voc07.py
2023-02-09 23:36:30,885 - mmdet - INFO - Epoch(val) [12][4952]	mAP: 0.7868, AP50: 0.7870
